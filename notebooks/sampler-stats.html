<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Sampler statistics &#8212; PyMC3 3.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="PyMC3 3.0 documentation" href="../index.html" />
    <link rel="up" title="Examples" href="../examples.html" />
    <link rel="next" title="Posterior Predictive Checks" href="posterior_predictive.html" />
    <link rel="prev" title="Examples" href="../examples.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="section" id="Sampler-statistics">
<h1>Sampler statistics<a class="headerlink" href="#Sampler-statistics" title="Permalink to this headline">¶</a></h1>
<p>When checking for convergence or when debugging a badly behaving
sampler, it is often helpful to take a closer look at what the sampler
is doing. For this purpose some samplers export statistics for each
generated sample.</p>
<div class="nbinput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sb</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<p>As a minimal example we sample from a standard normal distribution:</p>
<div class="nbinput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>
<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;mu1&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">NUTS</span><span class="p">()</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">njobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="stderr output_area container">
<div class="highlight"><pre>
100%|██████████| 2000/2000 [00:02&lt;00:00, 784.84it/s]
</pre></div></div>
</div>
<p>NUTS provides the following statistics:</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">trace</span><span class="o">.</span><span class="n">stat_names</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[5]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>{&#39;depth&#39;,
 &#39;diverging&#39;,
 &#39;energy&#39;,
 &#39;energy_error&#39;,
 &#39;max_energy_error&#39;,
 &#39;mean_tree_accept&#39;,
 &#39;step_size&#39;,
 &#39;step_size_bar&#39;,
 &#39;tree_size&#39;,
 &#39;tune&#39;}
</pre></div>
</div>
</div>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">mean_tree_accept</span></code>: The mean acceptance probability for the tree
that generated this sample. The mean of these values across all
samples but the burn-in should be approximately <code class="docutils literal"><span class="pre">target_accept</span></code>
(the default for this is 0.8).</li>
<li><code class="docutils literal"><span class="pre">diverging</span></code>: Whether the trajectory for this sample diverged. If
there are many diverging samples, this usually indicates that a
region of the posterior has high curvature. Reparametrization can
often help, but you can also try to increase <code class="docutils literal"><span class="pre">target_accept</span></code> to
something like 0.9 or 0.95.</li>
<li><code class="docutils literal"><span class="pre">energy</span></code>: The energy at the point in phase-space where the sample
was accepted. This can be used to identify posteriors with
problematically long tails. See below for an example.</li>
<li><code class="docutils literal"><span class="pre">energy_error</span></code>: The difference in energy between the start and the
end of the trajectory. For a perfect integrator this would always be
zero.</li>
<li><code class="docutils literal"><span class="pre">max_energy_error</span></code>: The maximum difference in energy along the
whole trajectory.</li>
<li><code class="docutils literal"><span class="pre">depth</span></code>: The depth of the tree that was used to generate this
sample</li>
<li><code class="docutils literal"><span class="pre">tree_size</span></code>: The number of leafs of the sampling tree, when the
sample was accepted. This is usually a bit less than
<span class="math">\(2 ^ \text{depth}\)</span>. If the tree size is large, the sampler is
using a lot of leapfrog steps to find the next sample. This can for
example happen if there are strong correlations in the posterior, if
the posterior has long tails, if there are regions of high curvature
(&#8220;funnels&#8221;), or if the variance estimates in the mass matrix are
inaccurate. Reparametrisation of the model or estimating the
posterior variances from past samples might help.</li>
<li><code class="docutils literal"><span class="pre">tune</span></code>: This is <code class="docutils literal"><span class="pre">True</span></code>, if step size adaptation was turned on
when this sample was generated.</li>
<li><code class="docutils literal"><span class="pre">step_size</span></code>: The step size used for this sample.</li>
<li><code class="docutils literal"><span class="pre">step_size_bar</span></code>: The current best known step-size. After the tuning
samples, the step size is set to this value. This should converge
during tuning.</li>
</ul>
<p>If the name of the statistic does not clash with the name of one of the
variables, we can use indexing to get the values. The values for the
chains will be concatenated.</p>
<p>We can see that the step sizes converged after the 1000 tuning samples
for both chains to about the same value. The first 2000 values are from
chain 1, the second 2000 from chain 2.</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;step_size_bar&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[5]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[&lt;matplotlib.lines.Line2D at 0x7ff11069c780&gt;]
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="output_area container">
<img alt="../_images/notebooks_sampler-stats_9_1.png" src="../_images/notebooks_sampler-stats_9_1.png" />
</div>
</div>
<p>The <code class="docutils literal"><span class="pre">get_sampler_stats</span></code> method provides more control over which values
should be returned, and it also works if the name of the statistic is
the same as the name of one of the variables. We can use the <code class="docutils literal"><span class="pre">chains</span></code>
option, to control values from which chain should be returned, or we can
set <code class="docutils literal"><span class="pre">combine=False</span></code> to get the values for the individual chains:</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">sizes1</span><span class="p">,</span> <span class="n">sizes2</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">get_sampler_stats</span><span class="p">(</span><span class="s1">&#39;depth&#39;</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes1</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[19]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[&lt;matplotlib.lines.Line2D at 0x7f1a7a222ba8&gt;]
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="output_area container">
<img alt="../_images/notebooks_sampler-stats_11_1.png" src="../_images/notebooks_sampler-stats_11_1.png" />
</div>
</div>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">accept</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">get_sampler_stats</span><span class="p">(</span><span class="s1">&#39;mean_tree_accept&#39;</span><span class="p">,</span> <span class="n">burn</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">sb</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[20]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1a7a1d7fd0&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="output_area container">
<img alt="../_images/notebooks_sampler-stats_12_1.png" src="../_images/notebooks_sampler-stats_12_1.png" />
</div>
</div>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">accept</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[21]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>0.81124010706223437
</pre></div>
</div>
</div>
<p>Find the index of all diverging transitions:</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;diverging&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[22]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>(array([], dtype=int64),)
</pre></div>
</div>
</div>
<p>It is often useful to compare the overall distribution of the energy
levels with the change of energy between successive samples. Ideally,
they should be very similar:</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">energy</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;energy&#39;</span><span class="p">]</span>
<span class="n">energy_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">energy</span><span class="p">)</span>
<span class="n">sb</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">energy</span> <span class="o">-</span> <span class="n">energy</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;energy&#39;</span><span class="p">)</span>
<span class="n">sb</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">energy_diff</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;energy diff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[23]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.legend.Legend at 0x7f1a7a72eba8&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="output_area container">
<img alt="../_images/notebooks_sampler-stats_17_1.png" src="../_images/notebooks_sampler-stats_17_1.png" />
</div>
</div>
<p>If the overall distribution of energy levels has longer tails, the
efficiency of the sampler will deteriorate quickly.</p>
</div>
<div class="section" id="Multiple-samplers">
<h1>Multiple samplers<a class="headerlink" href="#Multiple-samplers" title="Permalink to this headline">¶</a></h1>
<p>If multiple samplers are used for the same model (e.g. for continuous
and discrete variables), the exported values are merged or stacked along
a new axis.</p>
<div class="nbinput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>
<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">&quot;mu1&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">mu2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;mu2&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">step1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">BinaryMetropolis</span><span class="p">([</span><span class="n">mu1</span><span class="p">])</span>
    <span class="n">step2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Metropolis</span><span class="p">([</span><span class="n">mu2</span><span class="p">])</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="p">[</span><span class="n">step1</span><span class="p">,</span> <span class="n">step2</span><span class="p">],</span> <span class="n">njobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt empty container">
</div>
<div class="stderr output_area container">
<div class="highlight"><pre>
100%|██████████| 10000/10000 [00:03&lt;00:00, 2630.30it/s]
</pre></div></div>
</div>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">trace</span><span class="o">.</span><span class="n">stat_names</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[29]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>{&#39;accept&#39;, &#39;p_jump&#39;, &#39;tune&#39;}
</pre></div>
</div>
</div>
<p>Both samplers export <code class="docutils literal"><span class="pre">accept</span></code>, so we get one acceptance probability
for each sampler:</p>
<div class="nbinput container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">trace</span><span class="o">.</span><span class="n">get_sampler_stats</span><span class="p">(</span><span class="s1">&#39;accept&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[30]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>array([[  1.00000000e+00,   1.77752562e-03],
       [  2.50000000e-01,   7.91482991e-02],
       [  2.50000000e-01,   5.37823368e-03],
       ...,
       [  1.00000000e+00,   5.90932306e-03],
       [  1.00000000e+00,   1.02647227e+00],
       [  2.50000000e-01,   9.01210431e-04]])
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Sampler statistics</a></li>
<li><a class="reference internal" href="#Multiple-samplers">Multiple samplers</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../examples.html">Examples</a><ul>
      <li>Previous: <a href="../examples.html" title="previous chapter">Examples</a></li>
      <li>Next: <a href="posterior_predictive.html" title="next chapter">Posterior Predictive Checks</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/notebooks/sampler-stats.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, John Salvatier, Christopher Fonnesbeck, Thomas Wiecki.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../_sources/notebooks/sampler-stats.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>