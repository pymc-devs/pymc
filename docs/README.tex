




%___________________________________________________________________________

\hypertarget{purpose}{}
\pdfbookmark[0]{Purpose}{purpose}
\section*{Purpose}
\label{purpose}

PyMC is a python module that implements the Metropolis-Hastings algorithm as a
python class. It is extremely flexible and applicable to a large suite of
problems. PyMC includes methods for summarizing output, plotting, goodness-of-
fit and convergence diagnostics.


%___________________________________________________________________________

\hypertarget{features}{}
\pdfbookmark[0]{Features}{features}
\section*{Features}
\label{features}
\begin{itemize}
\item {} 
Implements the Metropolis-Hastings algorithm so you can focus on your
application instead of on gory numerical algorithms.

\item {} 
Define your distribution from 24 well-documented statistical distributions,

\item {} 
Summarize your results in tables and plots.

\item {} 
Run convergence diagnostics.

\end{itemize}


%___________________________________________________________________________

\hypertarget{what-s-new-in-2-0}{}
\pdfbookmark[0]{What's new in 2.0}{what-s-new-in-2-0}
\section*{What's new in 2.0}
\label{what-s-new-in-2-0}
\begin{itemize}

\item {} 
Added database backends: Select one from sqlite, MySQL, HDF5,
pickle files, text files or write a custom database backend from a template,

\item {} 
Added interactive mode: stop a sampling run in the middle, check progress, tweak it, save its state and restart the sampler
later,

\item {}
Added maximum a posteriori and normal approximation fitting methods,

\item {}
Separated model declaration from model fitting, so multiple fitting methods can be applied to the same model with no recoding,

\item {} 
Refactored MCMC code for extensibility and added an adaptive Metropolis step method for array-valued variables,

\item {} 
Added interactive convergence diagnostics,

\item {} 
Used decorators to improve code readability,

\item {} 
Sped up internal logic by coding the bottlenecks with Pyrex,

\item {}
Sped up MCMC computations by taking advantage of cancellations,

\item {} 
Sped up distributions by an optimization of the Fortran functions.

% \item {} 
% Seed multiple chains on different processors.

\end{itemize}


%___________________________________________________________________________

\hypertarget{usage}{}
\pdfbookmark[0]{Usage}{usage}
\section*{Usage}
\label{usage}

From a python shell, type:
\begin{quote}{\ttfamily \raggedright \noindent
import~pymc~\\
S~=~pymc.MCMC(model{\_}definition,~db='pickle')~\\
S.isample(iter=10000,~burn=5000,~thin=2)
}\end{quote}
where model{\_}definition is a module or iterable object containing variables, data and (possibly) factor potentials defining your problem. 

A module declaring the example model
\begin{eqnarray*}
        \begin{array}{ccc}
            (D_t | s, e, l) \sim \textup{Po}\left(r_t\right), & r_t=\left\{\begin{array}{ll}
                e & t\le s\\ l & t>s
                \end{array}\right.,&t\in[0,110]\\
            s\sim \textup{U}(0,110)\\
            e\sim \textup{Exp}(1)\\
            l\sim \textup{Exp}(1)        
        \end{array}
        \label{disastermodel} 
\end{eqnarray*}
where $D$ is data could be implemented as follows:
\begin{verbatim}
    import pymc
    import numpy

    s=pymc.Uniform('s',lower=0,upper=110)
    e=pymc.Exponential('e',beta=1)
    l=pymc.Exponential('l',beta=1)

    D_array=numpy.array([ 4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,
                          3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,
                          2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,
                          1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,
                          0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,
                          3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,
                          0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])

    @pymc.data
    @pymc.discrete_stochastic
    def D(value = D_array, s = s, e = e, l = l):
        return pymc.poisson_like(value[:s],e) \
        + pymc.poisson_like(value[s:],l)
\end{verbatim}
Read the \href{docs/pdf/new_interface.pdf}{user guide} for a
complete description of the package, classes and some examples to get started.


%___________________________________________________________________________

\hypertarget{history}{}
\pdfbookmark[0]{History}{history}
\section*{History}
\label{history}

PyMC began development in 2003, as an effort to generalize the process of building Metropolis-Hastimgs samplers, with an aim to making Markov chain Monte Carlo more accessible to non-statisticians (particularly ecologists). The choice to develop PyMC as a python module, rather than a standalone application, allowed the use MCMC methods in a larger modeling framework, in contrast to the BUGS environment. By 2005, PyMC was reliable enough for version 1.0 to be released to the public. A small group of regular users, most associated with the University of Georgia, provided much of the feedback necessary for the refinement of PyMC to its current state.

In 2006, David Huard and Anand Patil joined Chris Fonnesbeck on the development team for PyMC 2.0. This iteration of the software strives for more flexibility, better performance and a better end-user experience than any previous version of PyMC.


%___________________________________________________________________________

\