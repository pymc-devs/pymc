<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pymc.distributions &mdash; PyMC 2.3.4 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2.3.4',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="PyMC 2.3.4 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">PyMC 2.3.4 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pymc.distributions</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">pymc.distributions</span>

<span class="sd">A collection of common probability distributions. The objects associated</span>
<span class="sd">with a distribution called &#39;dist&#39; are:</span>

<span class="sd">  dist_like : function</span>
<span class="sd">    The log-likelihood function corresponding to dist. PyMC&#39;s convention</span>
<span class="sd">    is to sum the log-likelihoods of multiple input values, so all</span>
<span class="sd">    log-likelihood functions return a single float.</span>
<span class="sd">  rdist : function</span>
<span class="sd">    The random variate generator corresponding to dist. These take a</span>
<span class="sd">    &#39;size&#39; argument indicating how many variates should be generated.</span>
<span class="sd">  dist_expval : function</span>
<span class="sd">    Computes the expected value of a dist-distributed variable.</span>
<span class="sd">  Dist : Stochastic subclass</span>
<span class="sd">    Instances have dist_like as their log-probability function</span>
<span class="sd">    and rdist as their random function.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#-------------------------------------------------------------------</span>
<span class="c"># Decorate fortran functions from pymc.flib to ease argument passing</span>
<span class="c">#-------------------------------------------------------------------</span>
<span class="c"># TODO: Add exponweib_expval</span>
<span class="c"># TODO: categorical, mvhypergeometric</span>
<span class="c"># TODO: __all__</span>

<span class="n">__docformat__</span> <span class="o">=</span> <span class="s">&#39;reStructuredText&#39;</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">flib</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="c"># from scipy.stats.kde import gaussian_kde</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="kn">as</span> <span class="nn">stats</span>
<span class="n">gaussian_kde</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kde</span>
<span class="kn">from</span> <span class="nn">.Node</span> <span class="kn">import</span> <span class="n">ZeroProbability</span>
<span class="kn">from</span> <span class="nn">.PyMCObjects</span> <span class="kn">import</span> <span class="n">Stochastic</span><span class="p">,</span> <span class="n">Deterministic</span>
<span class="kn">from</span> <span class="nn">.CommonDeterministics</span> <span class="kn">import</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">pi</span><span class="p">,</span> <span class="n">inf</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">pdb</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">six</span>
<span class="kn">from</span> <span class="nn">.six</span> <span class="kn">import</span> <span class="n">print_</span>
<span class="nb">xrange</span> <span class="o">=</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">xrange</span>


<span class="k">def</span> <span class="nf">poiscdf</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">flib</span><span class="o">.</span><span class="n">gammq</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">())])</span>
    <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c"># Import utility functions</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="n">random_number</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span>
<span class="n">inverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span>

<span class="n">sc_continuous_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;beta&#39;</span><span class="p">,</span> <span class="s">&#39;cauchy&#39;</span><span class="p">,</span> <span class="s">&#39;chi2&#39;</span><span class="p">,</span>
                               <span class="s">&#39;degenerate&#39;</span><span class="p">,</span> <span class="s">&#39;exponential&#39;</span><span class="p">,</span> <span class="s">&#39;exponweib&#39;</span><span class="p">,</span>
                               <span class="s">&#39;gamma&#39;</span><span class="p">,</span> <span class="s">&#39;half_cauchy&#39;</span><span class="p">,</span> <span class="s">&#39;half_normal&#39;</span><span class="p">,</span>
                               <span class="s">&#39;inverse_gamma&#39;</span><span class="p">,</span> <span class="s">&#39;laplace&#39;</span><span class="p">,</span> <span class="s">&#39;logistic&#39;</span><span class="p">,</span>
                               <span class="s">&#39;lognormal&#39;</span><span class="p">,</span> <span class="s">&#39;noncentral_t&#39;</span><span class="p">,</span> <span class="s">&#39;normal&#39;</span><span class="p">,</span>
                               <span class="s">&#39;pareto&#39;</span><span class="p">,</span> <span class="s">&#39;t&#39;</span><span class="p">,</span> <span class="s">&#39;truncated_pareto&#39;</span><span class="p">,</span> <span class="s">&#39;uniform&#39;</span><span class="p">,</span>
                               <span class="s">&#39;weibull&#39;</span><span class="p">,</span> <span class="s">&#39;skew_normal&#39;</span><span class="p">,</span> <span class="s">&#39;truncated_normal&#39;</span><span class="p">,</span>
                               <span class="s">&#39;von_mises&#39;</span><span class="p">]</span>
<span class="n">sc_bool_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;bernoulli&#39;</span><span class="p">]</span>
<span class="n">sc_discrete_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;binomial&#39;</span><span class="p">,</span> <span class="s">&#39;betabin&#39;</span><span class="p">,</span> <span class="s">&#39;geometric&#39;</span><span class="p">,</span> <span class="s">&#39;poisson&#39;</span><span class="p">,</span>
                             <span class="s">&#39;negative_binomial&#39;</span><span class="p">,</span> <span class="s">&#39;categorical&#39;</span><span class="p">,</span> <span class="s">&#39;hypergeometric&#39;</span><span class="p">,</span>
                             <span class="s">&#39;discrete_uniform&#39;</span><span class="p">,</span> <span class="s">&#39;truncated_poisson&#39;</span><span class="p">]</span>

<span class="n">sc_nonnegative_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;bernoulli&#39;</span><span class="p">,</span> <span class="s">&#39;beta&#39;</span><span class="p">,</span> <span class="s">&#39;betabin&#39;</span><span class="p">,</span> <span class="s">&#39;binomial&#39;</span><span class="p">,</span> <span class="s">&#39;chi2&#39;</span><span class="p">,</span> <span class="s">&#39;exponential&#39;</span><span class="p">,</span>
                                <span class="s">&#39;exponweib&#39;</span><span class="p">,</span> <span class="s">&#39;gamma&#39;</span><span class="p">,</span> <span class="s">&#39;half_cauchy&#39;</span><span class="p">,</span> <span class="s">&#39;half_normal&#39;</span><span class="p">,</span>
                                <span class="s">&#39;hypergeometric&#39;</span><span class="p">,</span> <span class="s">&#39;inverse_gamma&#39;</span><span class="p">,</span> <span class="s">&#39;lognormal&#39;</span><span class="p">,</span>
                                <span class="s">&#39;weibull&#39;</span><span class="p">]</span>

<span class="n">mv_continuous_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;dirichlet&#39;</span><span class="p">,</span> <span class="s">&#39;mv_normal&#39;</span><span class="p">,</span>
                               <span class="s">&#39;mv_normal_cov&#39;</span><span class="p">,</span> <span class="s">&#39;mv_normal_chol&#39;</span><span class="p">,</span> <span class="s">&#39;wishart&#39;</span><span class="p">,</span>
                               <span class="s">&#39;wishart_cov&#39;</span><span class="p">]</span>

<span class="n">mv_discrete_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;multivariate_hypergeometric&#39;</span><span class="p">,</span> <span class="s">&#39;multinomial&#39;</span><span class="p">]</span>

<span class="n">mv_nonnegative_distributions</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;dirichlet&#39;</span><span class="p">,</span> <span class="s">&#39;wishart&#39;</span><span class="p">,</span>
                                <span class="s">&#39;wishart_cov&#39;</span><span class="p">,</span> <span class="s">&#39;multivariate_hypergeometric&#39;</span><span class="p">,</span>
                                <span class="s">&#39;multinomial&#39;</span><span class="p">]</span>

<span class="n">availabledistributions</span> <span class="o">=</span> <span class="p">(</span><span class="n">sc_continuous_distributions</span> <span class="o">+</span>
                          <span class="n">sc_bool_distributions</span> <span class="o">+</span>
                          <span class="n">sc_discrete_distributions</span> <span class="o">+</span>
                          <span class="n">mv_continuous_distributions</span> <span class="o">+</span>
                          <span class="n">mv_discrete_distributions</span><span class="p">)</span>

<span class="c"># Changes lower case, underscore-separated names into &quot;Class style&quot;</span>
<span class="c"># capitalized names For example, &#39;negative_binomial&#39; becomes</span>
<span class="c"># &#39;NegativeBinomial&#39;</span>
<span class="n">capitalize</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;_&#39;</span><span class="p">)])</span>


<span class="c"># ==============================================================================</span>
<span class="c"># User-accessible function to convert a logp and random function to a</span>
<span class="c"># Stochastic subclass.</span>
<span class="c"># ==============================================================================</span>

<span class="c"># TODO Document this function</span>
<span class="k">def</span> <span class="nf">bind_size</span><span class="p">(</span><span class="n">randfun</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">newfun</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">randfun</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="c"># Account for non-array return values</span>
            <span class="k">return</span> <span class="n">randfun</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">newfun</span><span class="o">.</span><span class="n">scalar_version</span> <span class="o">=</span> <span class="n">randfun</span>
    <span class="k">return</span> <span class="n">newfun</span>


<span class="k">def</span> <span class="nf">new_dist_class</span><span class="p">(</span><span class="o">*</span><span class="n">new_class_args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new class from a distribution.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      dtype : numpy dtype</span>
<span class="sd">        The dtype values of instances of this class.</span>
<span class="sd">      name : string</span>
<span class="sd">        Name of the new class.</span>
<span class="sd">      parent_names : list of strings</span>
<span class="sd">        The labels of the parents of this class.</span>
<span class="sd">      parents_default : list</span>
<span class="sd">        The default values of parents.</span>
<span class="sd">      docstr : string</span>
<span class="sd">        The docstring of this class.</span>
<span class="sd">      logp : function</span>
<span class="sd">        The log-probability function for this class.</span>
<span class="sd">      random : function</span>
<span class="sd">        The random function for this class.</span>
<span class="sd">      mv : boolean</span>
<span class="sd">        A flag indicating whether this class represents array-valued</span>
<span class="sd">        variables.</span>

<span class="sd">      .. note::</span>
<span class="sd">        stochastic_from_dist provides a higher-level version.</span>
<span class="sd">        stochastic_from_data is suited for non-parametric distributions.</span>

<span class="sd">      :SeeAlso:</span>
<span class="sd">        stochastic_from_dist, stochastic_from_data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="p">(</span><span class="n">dtype</span><span class="p">,</span>
     <span class="n">name</span><span class="p">,</span>
     <span class="n">parent_names</span><span class="p">,</span>
     <span class="n">parents_default</span><span class="p">,</span>
     <span class="n">docstr</span><span class="p">,</span>
     <span class="n">logp</span><span class="p">,</span>
     <span class="n">random</span><span class="p">,</span>
     <span class="n">mv</span><span class="p">,</span>
     <span class="n">logp_partial_gradients</span><span class="p">)</span> <span class="o">=</span> <span class="n">new_class_args</span>

    <span class="k">class</span> <span class="nc">new_class</span><span class="p">(</span><span class="n">Stochastic</span><span class="p">):</span>
        <span class="n">__doc__</span> <span class="o">=</span> <span class="n">docstr</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
            <span class="p">(</span><span class="n">dtype</span><span class="p">,</span>
             <span class="n">name</span><span class="p">,</span>
             <span class="n">parent_names</span><span class="p">,</span>
             <span class="n">parents_default</span><span class="p">,</span>
             <span class="n">docstr</span><span class="p">,</span>
             <span class="n">logp</span><span class="p">,</span>
             <span class="n">random</span><span class="p">,</span>
             <span class="n">mv</span><span class="p">,</span>
             <span class="n">logp_partial_gradients</span><span class="p">)</span> <span class="o">=</span> <span class="n">new_class_args</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="n">parents_default</span>

            <span class="c"># Figure out what argument names are needed.</span>
            <span class="n">arg_keys</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s">&#39;name&#39;</span><span class="p">,</span>
                <span class="s">&#39;parents&#39;</span><span class="p">,</span>
                <span class="s">&#39;value&#39;</span><span class="p">,</span>
                <span class="s">&#39;observed&#39;</span><span class="p">,</span>
                <span class="s">&#39;size&#39;</span><span class="p">,</span>
                <span class="s">&#39;trace&#39;</span><span class="p">,</span>
                <span class="s">&#39;rseed&#39;</span><span class="p">,</span>
                <span class="s">&#39;doc&#39;</span><span class="p">,</span>
                <span class="s">&#39;debug&#39;</span><span class="p">,</span>
                <span class="s">&#39;plot&#39;</span><span class="p">,</span>
                <span class="s">&#39;verbose&#39;</span><span class="p">]</span>
            <span class="n">arg_vals</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">None</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="s">&#39;isdata&#39;</span> <span class="ow">in</span> <span class="n">kwds</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s">&#39;&quot;isdata&quot; is deprecated, please use &quot;observed&quot; instead.&#39;</span><span class="p">)</span>
                <span class="n">kwds</span><span class="p">[</span><span class="s">&#39;observed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwds</span><span class="p">[</span><span class="s">&#39;isdata&#39;</span><span class="p">]</span>
                <span class="k">pass</span>

            <span class="c"># No size argument allowed for multivariate distributions.</span>
            <span class="k">if</span> <span class="n">mv</span><span class="p">:</span>
                <span class="n">arg_keys</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
                <span class="n">arg_vals</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

            <span class="n">arg_dict_out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">arg_keys</span><span class="p">,</span> <span class="n">arg_vals</span><span class="p">))</span>
            <span class="n">args_needed</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">parent_names</span> <span class="o">+</span> <span class="n">arg_keys</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

            <span class="c"># Sort positional arguments</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">args_needed</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">parent_names</span><span class="p">:</span>
                        <span class="n">parents</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">arg_dict_out</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s">&#39;Too many positional arguments provided. Arguments for class &#39;</span> <span class="o">+</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span> <span class="o">+</span>
                        <span class="s">&#39; are: &#39;</span> <span class="o">+</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">args_needed</span><span class="p">))</span>

            <span class="c"># Sort keyword arguments</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">args_needed</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">parent_names</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">parents</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">parents_default</span><span class="p">:</span>
                            <span class="n">parents</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">parents_default</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;No value given for parent &#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">arg_dict_out</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">arg_dict_out</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">pass</span>

            <span class="c"># Remaining unrecognized arguments raise an error.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s">&#39;Keywords &#39;</span> <span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="n">kwds</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span>
                                <span class="s">&#39; not recognized. Arguments recognized are &#39;</span> <span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="n">args_needed</span><span class="p">))</span>

        <span class="c"># Determine size desired for scalar variables.</span>
        <span class="c"># Notes</span>
        <span class="c"># -----</span>
        <span class="c"># Case | init_val     | parents       | size | value.shape | bind size</span>
        <span class="c"># ------------------------------------------------------------------</span>
        <span class="c"># 1.1  | None         | scalars       | None | 1           | 1</span>
        <span class="c"># 1.2  | None         | scalars       | n    | n           | n</span>
        <span class="c"># 1.3  | None         | n             | None | n           | 1</span>
        <span class="c"># 1.4  | None         | n             | n(m) | n (Error)   | 1 (-)</span>
        <span class="c"># 2.1  | scalar       | scalars       | None | 1           | 1</span>
        <span class="c"># 2.2  | scalar       | scalars       | n    | n           | n</span>
        <span class="c"># 2.3  | scalar       | n             | None | n           | 1</span>
        <span class="c"># 2.4  | scalar       | n             | n(m) | n (Error)   | 1 (-)</span>
        <span class="c"># 3.1  | n            | scalars       | None | n           | n</span>
        <span class="c"># 3.2  | n            | scalars       | n(m) | n (Error)   | n (-)</span>
        <span class="c"># 3.3  | n            | n             | None | n           | 1</span>
        <span class="c"># 3.4  | n            | n             | n(m) | n (Error)   | 1 (-)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">mv</span><span class="p">:</span>

                <span class="n">shape</span> <span class="o">=</span> <span class="n">arg_dict_out</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;size&#39;</span><span class="p">)</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>

                <span class="n">init_val</span> <span class="o">=</span> <span class="n">arg_dict_out</span><span class="p">[</span><span class="s">&#39;value&#39;</span><span class="p">]</span>
                <span class="n">init_val_shape</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">init_val</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span>
                    <span class="n">init_val</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">pv</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parents</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
                    <span class="n">biggest_parent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span>
                        <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pv</span><span class="p">])</span>
                    <span class="n">parents_shape</span> <span class="o">=</span> <span class="n">pv</span><span class="p">[</span><span class="n">biggest_parent</span><span class="p">]</span>

                    <span class="c"># Scalar parents can support any shape.</span>
                    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">parents_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">parents_shape</span> <span class="o">=</span> <span class="bp">None</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">parents_shape</span> <span class="o">=</span> <span class="bp">None</span>

                <span class="k">def</span> <span class="nf">shape_error</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s">&#39;Shapes are incompatible: value </span><span class="si">%s</span><span class="s">, largest parent </span><span class="si">%s</span><span class="s">, shape argument </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
                        <span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">init_val_shape</span><span class="p">,</span> <span class="n">parents_shape</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">init_val_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">init_val_shape</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">:</span>
                    <span class="n">shape_error</span><span class="p">()</span>

                <span class="n">given_shape</span> <span class="o">=</span> <span class="n">init_val_shape</span> <span class="ow">or</span> <span class="n">shape</span>
                <span class="n">bindshape</span> <span class="o">=</span> <span class="n">given_shape</span> <span class="ow">or</span> <span class="n">parents_shape</span>

                <span class="c"># Check consistency of bindshape and parents_shape</span>
                <span class="k">if</span> <span class="n">parents_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="c"># Uncomment to leave broadcasting completely up to NumPy&#39;s random functions</span>
                    <span class="c"># if bindshape[-np.alen(parents_shape):]!=parents_shape:</span>
                    <span class="c"># Uncomment to limit broadcasting flexibility to what the</span>
                    <span class="c"># Fortran likelihoods can handle.</span>
                    <span class="k">if</span> <span class="n">bindshape</span> <span class="o">&lt;</span> <span class="n">parents_shape</span><span class="p">:</span>
                        <span class="n">shape_error</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">random</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">random</span> <span class="o">=</span> <span class="n">bind_size</span><span class="p">(</span><span class="n">random</span><span class="p">,</span> <span class="n">bindshape</span><span class="p">)</span>

            <span class="k">elif</span> <span class="s">&#39;size&#39;</span> <span class="ow">in</span> <span class="n">kwds</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s">&#39;No size argument allowed for multivariate stochastic variables.&#39;</span><span class="p">)</span>

            <span class="c"># Call base class initialization method</span>
            <span class="k">if</span> <span class="n">arg_dict_out</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;debug&#39;</span><span class="p">):</span>
                <span class="n">logp</span> <span class="o">=</span> <span class="n">debug_wrapper</span><span class="p">(</span><span class="n">logp</span><span class="p">)</span>
                <span class="n">random</span> <span class="o">=</span> <span class="n">debug_wrapper</span><span class="p">(</span><span class="n">random</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Stochastic</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="n">logp</span><span class="o">=</span><span class="n">logp</span><span class="p">,</span>
                    <span class="n">random</span><span class="o">=</span><span class="n">random</span><span class="p">,</span>
                    <span class="n">logp_partial_gradients</span><span class="o">=</span><span class="n">logp_partial_gradients</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">arg_dict_out</span><span class="p">)</span>

    <span class="n">new_class</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">new_class</span><span class="o">.</span><span class="n">parent_names</span> <span class="o">=</span> <span class="n">parent_names</span>
    <span class="n">new_class</span><span class="o">.</span><span class="n">parents_default</span> <span class="o">=</span> <span class="n">parents_default</span>
    <span class="n">new_class</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">new_class</span><span class="o">.</span><span class="n">mv</span> <span class="o">=</span> <span class="n">mv</span>
    <span class="n">new_class</span><span class="o">.</span><span class="n">raw_fns</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;logp&#39;</span><span class="p">:</span> <span class="n">logp</span><span class="p">,</span> <span class="s">&#39;random&#39;</span><span class="p">:</span> <span class="n">random</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">new_class</span>


<span class="k">def</span> <span class="nf">stochastic_from_dist</span><span class="p">(</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">logp</span><span class="p">,</span> <span class="n">random</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">logp_partial_gradients</span><span class="o">=</span><span class="p">{},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">mv</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Stochastic subclass made from a particular distribution.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      name : string</span>
<span class="sd">        The name of the new class.</span>
<span class="sd">      logp : function</span>
<span class="sd">        The log-probability function.</span>
<span class="sd">      random : function</span>
<span class="sd">        The random function</span>
<span class="sd">      dtype : numpy dtype</span>
<span class="sd">        The dtype of values of instances.</span>
<span class="sd">      mv : boolean</span>
<span class="sd">        A flag indicating whether this class represents</span>
<span class="sd">        array-valued variables.</span>

<span class="sd">    :Example:</span>
<span class="sd">      &gt;&gt;&gt; Exponential = stochastic_from_dist(&#39;exponential&#39;,</span>
<span class="sd">                                              logp=exponential_like,</span>
<span class="sd">                                              random=rexponential,</span>
<span class="sd">                                              dtype=np.float,</span>
<span class="sd">                                              mv=False)</span>
<span class="sd">      &gt;&gt;&gt; A = Exponential(self_name, value, beta)</span>

<span class="sd">    .. note::</span>
<span class="sd">      new_dist_class is a more flexible class factory. Also consider</span>
<span class="sd">      subclassing Stochastic directly.</span>
<span class="sd">      stochastic_from_data is suited for non-parametric distributions.</span>

<span class="sd">    :SeeAlso:</span>
<span class="sd">      new_dist_class, stochastic_from_data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">varargs</span><span class="p">,</span> <span class="n">varkw</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getargspec</span><span class="p">(</span><span class="n">logp</span><span class="p">)</span>
    <span class="n">parent_names</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">parents_default</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">defaults</span><span class="p">):],</span> <span class="n">defaults</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>  <span class="c"># No parents at all.</span>
        <span class="n">parents_default</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">name</span> <span class="o">=</span> <span class="n">capitalize</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="c"># Build docstring from distribution</span>
    <span class="n">parents_str</span> <span class="o">=</span> <span class="s">&#39;&#39;</span>
    <span class="k">if</span> <span class="n">parent_names</span><span class="p">:</span>
        <span class="n">parents_str</span> <span class="o">=</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parent_names</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39;, &#39;</span>
    <span class="n">docstr</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s">&#39; = &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> \
        <span class="s">&#39;(name, &#39;</span> <span class="o">+</span> <span class="n">parents_str</span> <span class="o">+</span> <span class="s">&#39;value=None, observed=False,&#39;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">mv</span><span class="p">:</span>
        <span class="n">docstr</span> <span class="o">+=</span> <span class="s">&#39; size=1,&#39;</span>
    <span class="n">docstr</span> <span class="o">+=</span> <span class="s">&#39; trace=True, rseed=True, doc=None, verbose=-1, debug=False)</span><span class="se">\n\n</span><span class="s">&#39;</span>
    <span class="n">docstr</span> <span class="o">+=</span> <span class="s">&#39;Stochastic variable with &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> \
        <span class="s">&#39; distribution.</span><span class="se">\n</span><span class="s">Parents are: &#39;</span> <span class="o">+</span> <span class="s">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parent_names</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39;.</span><span class="se">\n\n</span><span class="s">&#39;</span>
    <span class="n">docstr</span> <span class="o">+=</span> <span class="s">&#39;Docstring of log-probability function:</span><span class="se">\n</span><span class="s">&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">docstr</span> <span class="o">+=</span> <span class="n">logp</span><span class="o">.</span><span class="n">__doc__</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c"># This will happen when logp doesn&#39;t have a docstring</span>

    <span class="n">logp</span> <span class="o">=</span> <span class="n">valuewrapper</span><span class="p">(</span><span class="n">logp</span><span class="p">)</span>
    <span class="n">distribution_arguments</span> <span class="o">=</span> <span class="n">logp</span><span class="o">.</span><span class="n">__dict__</span>

    <span class="n">wrapped_logp_partial_gradients</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">parameter</span><span class="p">,</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">logp_partial_gradients</span><span class="p">):</span>
        <span class="n">wrapped_logp_partial_gradients</span><span class="p">[</span><span class="n">parameter</span><span class="p">]</span> <span class="o">=</span> <span class="n">valuewrapper</span><span class="p">(</span>
            <span class="n">logp_partial_gradients</span><span class="p">[</span><span class="n">parameter</span><span class="p">],</span>
            <span class="n">arguments</span><span class="o">=</span><span class="n">distribution_arguments</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_dist_class</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">parent_names</span><span class="p">,</span> <span class="n">parents_default</span><span class="p">,</span> <span class="n">docstr</span><span class="p">,</span>
                          <span class="n">logp</span><span class="p">,</span> <span class="n">random</span><span class="p">,</span> <span class="n">mv</span><span class="p">,</span> <span class="n">wrapped_logp_partial_gradients</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">stochastic_from_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
                         <span class="n">value</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Stochastic subclass made from arbitrary data.</span>

<span class="sd">    The histogram for the data is fitted with Kernel Density Estimation.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `data`  : An array with samples (e.g. trace[:])</span>
<span class="sd">      - `lower` : Lower bound on possible outcomes</span>
<span class="sd">      - `upper` : Upper bound on possible outcomes</span>

<span class="sd">    :Example:</span>
<span class="sd">       &gt;&gt;&gt; from pymc import stochastic_from_data</span>
<span class="sd">       &gt;&gt;&gt; pos = stochastic_from_data(&#39;posterior&#39;, posterior_samples)</span>
<span class="sd">       &gt;&gt;&gt; prior = pos # update the prior with arbitrary distributions</span>

<span class="sd">    :Alias:</span>
<span class="sd">      Histogram</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">gaussian_kde</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c"># automatic bandwidth selection</span>

    <span class="c"># account for tail contribution</span>
    <span class="n">lower_tail</span> <span class="o">=</span> <span class="n">upper_tail</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">if</span> <span class="n">lower</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
        <span class="n">lower_tail</span> <span class="o">=</span> <span class="n">pdf</span><span class="o">.</span><span class="n">integrate_box</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">lower</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">upper</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
        <span class="n">upper_tail</span> <span class="o">=</span> <span class="n">pdf</span><span class="o">.</span><span class="n">integrate_box</span><span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">lower_tail</span> <span class="o">+</span> <span class="n">upper_tail</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">logp</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">*</span> <span class="n">pdf</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="n">lower</span> <span class="ow">or</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">upper</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">elif</span> <span class="n">prob</span> <span class="o">&lt;=</span> <span class="mf">0.</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">random</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">pdf</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">while</span> <span class="n">res</span> <span class="o">&lt;</span> <span class="n">lower</span> <span class="ow">or</span> <span class="n">res</span> <span class="o">&gt;</span> <span class="n">upper</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">pdf</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">Stochastic</span><span class="p">(</span><span class="n">logp</span><span class="o">=</span><span class="n">logp</span><span class="p">,</span>
                      <span class="n">doc</span><span class="o">=</span><span class="s">&#39;Non-parametric density with Gaussian Kernels.&#39;</span><span class="p">,</span>
                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                      <span class="n">parents</span><span class="o">=</span><span class="p">{},</span>
                      <span class="n">random</span><span class="o">=</span><span class="n">random</span><span class="p">,</span>
                      <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span>
                      <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                      <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                      <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>


<span class="c"># Alias following Stochastics naming convention</span>
<span class="n">Histogram</span> <span class="o">=</span> <span class="n">stochastic_from_data</span>

<span class="c">#-------------------------------------------------------------</span>
<span class="c"># Light decorators</span>
<span class="c">#-------------------------------------------------------------</span>


<span class="k">def</span> <span class="nf">randomwrap</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decorator for random value generators</span>

<span class="sd">    Allows passing of sequence of parameters, as well as a size argument.</span>


<span class="sd">    Convention:</span>

<span class="sd">      - If size=1 and the parameters are all scalars, return a scalar.</span>
<span class="sd">      - If size=1, the random variates are 1D.</span>
<span class="sd">      - If the parameters are scalars and size &gt; 1, the random variates are 1D.</span>
<span class="sd">      - If size &gt; 1 and the parameters are sequences, the random variates are</span>
<span class="sd">        aligned as (size, max(length)), where length is the parameters size.</span>


<span class="sd">    :Example:</span>
<span class="sd">      &gt;&gt;&gt; rbernoulli(.1)</span>
<span class="sd">      0</span>
<span class="sd">      &gt;&gt;&gt; rbernoulli([.1,.9])</span>
<span class="sd">      np.asarray([0, 1])</span>
<span class="sd">      &gt;&gt;&gt; rbernoulli(.9, size=2)</span>
<span class="sd">      np.asarray([1, 1])</span>
<span class="sd">      &gt;&gt;&gt; rbernoulli([.1,.9], 2)</span>
<span class="sd">      np.asarray([[0, 1],</span>
<span class="sd">             [0, 1]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c"># Find the order of the arguments.</span>
    <span class="n">refargs</span><span class="p">,</span> <span class="n">varargs</span><span class="p">,</span> <span class="n">varkw</span><span class="p">,</span> <span class="n">defaults</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getargspec</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="c"># vfunc = np.vectorize(self.func)</span>
    <span class="n">npos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">refargs</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">defaults</span><span class="p">)</span>  <span class="c"># Number of pos. arg.</span>
    <span class="n">nkwds</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">defaults</span><span class="p">)</span>  <span class="c"># Number of kwds args.</span>
    <span class="n">mv</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">__name__</span><span class="p">[</span>
        <span class="mi">1</span><span class="p">:]</span> <span class="ow">in</span> <span class="n">mv_continuous_distributions</span> <span class="o">+</span> <span class="n">mv_discrete_distributions</span>

    <span class="c"># Use the NumPy random function directly if this is not a multivariate</span>
    <span class="c"># distribution</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">mv</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
        <span class="c"># First transform keyword arguments into positional arguments.</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nkwds</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">refargs</span><span class="p">[</span><span class="n">n</span><span class="p">:]):</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">kwds</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kwds</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">defaults</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="n">npos</span> <span class="o">+</span> <span class="n">i</span><span class="p">])</span>

        <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">largs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">nr</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">length</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
        <span class="n">dimension</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">ndim</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dimension</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="s">&#39;Dimensions do not agree.&#39;</span><span class="p">)</span>
        <span class="c"># Make sure all elements are iterable and have consistent lengths, ie</span>
        <span class="c"># 1 or n, but not m and n.</span>

        <span class="k">for</span> <span class="n">arg</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">arr</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">s</span> <span class="o">==</span> <span class="n">N</span><span class="p">:</span>
                <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s">&#39;Arguments size not allowed: </span><span class="si">%s</span><span class="s">.&#39;</span> <span class="o">%</span> <span class="n">s</span><span class="p">)</span>
            <span class="n">largs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mv</span> <span class="ow">and</span> <span class="n">N</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">max</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">nr</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s">&#39;Multivariate distributions cannot take s&gt;1 and multiple values.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mv</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">arg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">largs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">largs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">largs</span><span class="p">):</span>
            <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">arg</span><span class="p">))</span>

        <span class="n">size</span> <span class="o">=</span> <span class="n">arg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">vec_stochastics</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">mv</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">nr</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">vec_stochastics</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="k">elif</span> <span class="n">vec_stochastics</span> <span class="ow">or</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c"># Scalar case</span>
                <span class="k">return</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">wrapper</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">__doc__</span>
    <span class="n">wrapper</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">__name__</span>
    <span class="k">return</span> <span class="n">wrapper</span>


<span class="k">def</span> <span class="nf">debug_wrapper</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="c"># Wrapper to debug distributions</span>

    <span class="kn">import</span> <span class="nn">pdb</span>

    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="n">print_</span><span class="p">(</span><span class="s">&#39;Debugging inside </span><span class="si">%s</span><span class="s">:&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
        <span class="n">print_</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">Press </span><span class="se">\&#39;</span><span class="s">s</span><span class="se">\&#39;</span><span class="s"> to step into function for debugging&#39;</span><span class="p">)</span>
        <span class="n">print_</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">Call </span><span class="se">\&#39;</span><span class="s">args</span><span class="se">\&#39;</span><span class="s"> to list function arguments&#39;</span><span class="p">)</span>

        <span class="c"># Set debugging trace</span>
        <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>

        <span class="c"># Call function</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">wrapper</span>


<span class="c">#-------------------------------------------------------------</span>
<span class="c"># Utility functions</span>
<span class="c">#-------------------------------------------------------------</span>

<span class="k">def</span> <span class="nf">constrain</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">,</span> <span class="n">allow_equal</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply interval constraint on stochastic value.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ok</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">constrain</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">allow_equal</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ok</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">ZeroProbability</span>


<span class="k">def</span> <span class="nf">standardize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Standardize x</span>

<span class="sd">    Return (x-loc)/scale</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">standardize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

<span class="c"># ==================================</span>
<span class="c"># = vectorize causes memory leaks. =</span>
<span class="c"># ==================================</span>
<span class="c"># @Vectorize</span>


<span class="k">def</span> <span class="nf">gammaln</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logarithm of the Gamma function</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamfun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">expand_triangular</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expand flattened triangular matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="c"># Unflatten matrix</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
        <span class="p">[[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">k</span> <span class="o">-</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)])</span>
    <span class="c"># Loop over rows</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="c"># Loop over columns</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">Y</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Y</span>


<span class="c"># Loss functions</span>

<span class="n">absolute_loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">absolute</span><span class="p">(</span><span class="n">o</span> <span class="o">-</span> <span class="n">e</span><span class="p">)</span>

<span class="n">squared_loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="n">o</span> <span class="o">-</span> <span class="n">e</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

<span class="n">chi_square_loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">*</span> <span class="p">(</span><span class="n">o</span> <span class="o">-</span> <span class="n">e</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">e</span>

<span class="n">loss_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;absolute&#39;</span><span class="p">:</span> <span class="n">absolute_loss</span><span class="p">,</span>
    <span class="s">&#39;squared&#39;</span><span class="p">:</span> <span class="n">squared_loss</span><span class="p">,</span>
    <span class="s">&#39;chi_square&#39;</span><span class="p">:</span> <span class="n">chi_square_loss</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">GOFpoints</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">expval</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="c"># Return pairs of points for GOF calculation</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">expval</span><span class="p">),</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">expval</span><span class="p">)]),</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gofwrapper</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="s">&#39;squared&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Goodness-of-fit decorator function for likelihoods</span>
<span class="sd">    ==================================================</span>
<span class="sd">    Generates goodness-of-fit points for data likelihoods.</span>

<span class="sd">    Wrap function f(*args, **kwds) where f is a likelihood.</span>

<span class="sd">    Assume args = (x, parameter1, parameter2, ...)</span>
<span class="sd">    Before passing the arguments to the function, the wrapper makes sure that</span>
<span class="sd">    the parameters have the same shape as x.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span>
    <span class="c"># Take a snapshot of the main namespace.</span>

    <span class="c"># Find the functions needed to compute the gof points.</span>
    <span class="n">expval_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;_expval&#39;</span><span class="p">)</span>
    <span class="n">random_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="s">&#39;r&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This wraps a likelihood.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="sd">&quot;&quot;&quot;Return gof points.&quot;&quot;&quot;</span>

        <span class="c"># Calculate loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;gof&#39;</span><span class="p">,</span> <span class="n">loss_functions</span><span class="p">[</span><span class="n">loss_function</span><span class="p">])</span>

        <span class="c"># Expected value, given parameters</span>
        <span class="n">expval</span> <span class="o">=</span> <span class="n">expval_func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">random_func</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">*</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">gof_points</span> <span class="o">=</span> <span class="n">GOFpoints</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">expval</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

        <span class="sd">&quot;&quot;&quot;Return likelihood.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

    <span class="c"># Assign function attributes to wrapper.</span>
    <span class="n">wrapper</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">__doc__</span>
    <span class="n">wrapper</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span>
    <span class="n">wrapper</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="k">return</span> <span class="n">wrapper</span>

<span class="c">#--------------------------------------------------------</span>
<span class="c"># Statistical distributions</span>
<span class="c"># random generator, expval, log-likelihood</span>
<span class="c">#--------------------------------------------------------</span>

<span class="c"># Autoregressive lognormal</span>


<span class="k">def</span> <span class="nf">rarlognormal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Autoregressive normal random variates.</span>

<span class="sd">    If a is a scalar, generates one series of length size.</span>
<span class="sd">    If a is a sequence, generates size series of the same length</span>
<span class="sd">    as a.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ar1</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">arlognormal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Autoregressive lognormal log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        x_i &amp; = a_i \exp(e_i) \\</span>
<span class="sd">        e_i &amp; = \rho e_{i-1} + \epsilon_i</span>

<span class="sd">    where :math:`\epsilon_i \sim N(0,\sigma)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">arlognormal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="c"># Bernoulli----------------------------------------------</span>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rbernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random Bernoulli variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p</span>


<span class="k">def</span> <span class="nf">bernoulli_expval</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of bernoulli distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">p</span>


<div class="viewcode-block" id="bernoulli_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.bernoulli_like">[docs]</a><span class="k">def</span> <span class="nf">bernoulli_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;Bernoulli log-likelihood</span>

<span class="sd">    The Bernoulli distribution describes the probability of successes (x=1) and</span>
<span class="sd">    failures (x=0).</span>

<span class="sd">    .. math::  f(x \mid p) = p^{x} (1-p)^{1-x}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Series of successes (1) and failures (0). :math:`x=0,1`</span>
<span class="sd">      - `p` : Probability of success. :math:`0 &lt; p &lt; 1`.</span>

<span class="sd">    :Example:</span>
<span class="sd">       &gt;&gt;&gt; from pymc import bernoulli_like</span>
<span class="sd">       &gt;&gt;&gt; bernoulli_like([0,1,0,1], .4)</span>
<span class="sd">       -2.854232711280291</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(x)= p`</span>
<span class="sd">      - :math:`Var(x)= p(1-p)`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</div>
<span class="n">bernoulli_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">bern_grad_p</span><span class="p">}</span>

<span class="c"># Beta----------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rbeta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random beta variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="kn">import</span> <span class="n">beta</span> <span class="k">as</span> <span class="n">sbeta</span>
    <span class="k">return</span> <span class="n">sbeta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="p">),</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="c"># return np.random.beta(alpha, beta, size)</span>


<span class="k">def</span> <span class="nf">beta_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of beta distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">)</span>


<div class="viewcode-block" id="beta_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.beta_like">[docs]</a><span class="k">def</span> <span class="nf">beta_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Beta log-likelihood. The conjugate prior for the parameter</span>
<span class="sd">    :math:`p` of the binomial distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} x^{\alpha - 1} (1 - x)^{\beta - 1}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : 0 &lt; x &lt; 1</span>
<span class="sd">      - `alpha` : alpha &gt; 0</span>
<span class="sd">      - `beta` : beta &gt; 0</span>

<span class="sd">    :Example:</span>
<span class="sd">      &gt;&gt;&gt; from pymc import beta_like</span>
<span class="sd">      &gt;&gt;&gt; beta_like(.4,1,2)</span>
<span class="sd">      0.182321556793954</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X)=\frac{\alpha}{\alpha+\beta}`</span>
<span class="sd">      - :math:`Var(X)=\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># try:</span>
    <span class="c">#     constrain(alpha, lower=0, allow_equal=True)</span>
    <span class="c">#     constrain(beta, lower=0, allow_equal=True)</span>
    <span class="c">#     constrain(x, 0, 1, allow_equal=True)</span>
    <span class="c"># except ZeroProbability:</span>
    <span class="c">#     return -np.Inf</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">beta_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</div>
<span class="n">beta_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">beta_grad_x</span><span class="p">,</span>
                  <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">beta_grad_a</span><span class="p">,</span>
                  <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">beta_grad_b</span><span class="p">}</span>


<span class="c"># Binomial----------------------------------------------</span>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rbinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random binomial variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># return np.random.binomial(n,p,size)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">binomial_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of binomial distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">p</span> <span class="o">*</span> <span class="n">n</span>


<div class="viewcode-block" id="binomial_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.binomial_like">[docs]</a><span class="k">def</span> <span class="nf">binomial_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Binomial log-likelihood.  The discrete probability distribution of the</span>
<span class="sd">    number of successes in a sequence of n independent yes/no experiments,</span>
<span class="sd">    each of which yields success with probability p.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid n, p) = \frac{n!}{x!(n-x)!} p^x (1-p)^{n-x}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] Number of successes, &gt; 0.</span>
<span class="sd">      - `n` : [int] Number of Bernoulli trials, &gt; x.</span>
<span class="sd">      - `p` : Probability of success in each trial, :math:`p \in [0,1]`.</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(X)=np`</span>
<span class="sd">       - :math:`Var(X)=np(1-p)`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c"># Temporary hack to avoid issue #614</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</div>
<span class="n">binomial_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">binomial_gp</span><span class="p">}</span>

<span class="c"># Beta----------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rbetabin</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random beta-binomial variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">phi</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">betabin_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of beta-binomial distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">n</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">betabin_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Beta-binomial log-likelihood. Equivalent to binomial random</span>
<span class="sd">    variables with probabilities drawn from a</span>
<span class="sd">    :math:`\texttt{Beta}(\alpha,\beta)` distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta, n) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)} \frac{\Gamma(n+1)}{\Gamma(x+1)\Gamma(n-x+1)} \frac{\Gamma(\alpha + x)\Gamma(n+\beta-x)}{\Gamma(\alpha+\beta+n)}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x=0,1,\ldots,n</span>
<span class="sd">      - `alpha` : alpha &gt; 0</span>
<span class="sd">      - `beta` : beta &gt; 0</span>
<span class="sd">      - `n` : n=x,x+1,\ldots</span>

<span class="sd">    :Example:</span>
<span class="sd">      &gt;&gt;&gt; betabin_like(3,1,1,10)</span>
<span class="sd">      -2.3978952727989</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X)=n\frac{\alpha}{\alpha+\beta}`</span>
<span class="sd">      - :math:`Var(X)=n\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">betabin_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">betabin_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">betabin_ga</span><span class="p">,</span>
                     <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">betabin_gb</span><span class="p">}</span>

<span class="c"># Categorical----------------------------------------------</span>
<span class="c"># Note that because categorical elements are not ordinal, there</span>
<span class="c"># is no expected value.</span>

<span class="c">#@randomwrap</span>


<span class="k">def</span> <span class="nf">rcategorical</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Categorical random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">rcat</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span>


<div class="viewcode-block" id="categorical_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.categorical_like">[docs]</a><span class="k">def</span> <span class="nf">categorical_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Categorical log-likelihood. The most general discrete distribution.</span>

<span class="sd">    .. math::  f(x=i \mid p) = p_i</span>

<span class="sd">    for :math:`i \in 0 \ldots k-1`.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] :math:`x \in 0\ldots k-1`</span>
<span class="sd">      - `p` : [float] :math:`p &gt; 0`, :math:`\sum p = 1`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.0001</span><span class="p">):</span>
        <span class="n">print_</span><span class="p">(</span><span class="s">&quot;Probabilities in categorical_like sum to&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">categorical</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>


<span class="c"># Cauchy----------------------------------------------</span></div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rcauchy</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns Cauchy random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tan</span><span class="p">(</span><span class="n">pi</span> <span class="o">*</span> <span class="n">random_number</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">-</span> <span class="n">pi</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cauchy_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of cauchy distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">alpha</span>

<span class="c"># In wikipedia, the arguments name are k, x0.</span>


<div class="viewcode-block" id="cauchy_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.cauchy_like">[docs]</a><span class="k">def</span> <span class="nf">cauchy_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Cauchy log-likelihood. The Cauchy distribution is also known as the</span>
<span class="sd">    Lorentz or the Breit-Wigner distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{1}{\pi \beta [1 + (\frac{x-\alpha}{\beta})^2]}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `alpha` : Location parameter.</span>
<span class="sd">      - `beta` : Scale parameter &gt; 0.</span>

<span class="sd">    .. note::</span>
<span class="sd">       - Mode and median are at alpha.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">cauchy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</div>
<span class="n">cauchy_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">cauchy_grad_x</span><span class="p">,</span>
                    <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">cauchy_grad_a</span><span class="p">,</span>
                    <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">cauchy_grad_b</span><span class="p">}</span>

<span class="c"># Chi square----------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rchi2</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random :math:`\chi^2` variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">chi2_expval</span><span class="p">(</span><span class="n">nu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Chi-squared distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">nu</span>


<div class="viewcode-block" id="chi2_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.chi2_like">[docs]</a><span class="k">def</span> <span class="nf">chi2_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Chi-squared :math:`\chi^2` log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \nu) = \frac{x^{(\nu-2)/2}e^{-x/2}}{2^{\nu/2}\Gamma(\nu/2)}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : &gt; 0</span>
<span class="sd">      - `nu` : [int] Degrees of freedom ( nu &gt; 0 )</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X)=\nu`</span>
<span class="sd">      - :math:`Var(X)=2\nu`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nu</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</div>
<span class="n">chi2_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nu</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
                  <span class="s">&#39;nu&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_alpha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nu</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="o">.</span><span class="mi">5</span><span class="p">}</span>

<span class="c"># chi2_grad_like = {&#39;x&#39;  : lambda x, nu : (nu / 2 - 1) / x -.5,</span>
<span class="c">#                  &#39;nu&#39; : flib.chi2_grad_nu }</span>

<span class="c"># Degenerate---------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rdegenerate</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random degenerate variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span>


<span class="k">def</span> <span class="nf">degenerate_expval</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of degenerate distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">k</span>


<div class="viewcode-block" id="degenerate_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.degenerate_like">[docs]</a><span class="k">def</span> <span class="nf">degenerate_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Degenerate log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid k) = \left\{ \begin{matrix} 1 \text{ if } x = k \\ 0 \text{ if } x \ne k\end{matrix} \right.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input value.</span>
<span class="sd">      - `k` : Degenerate value.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">([</span><span class="n">i</span> <span class="o">==</span> <span class="n">k</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]))</span>

<span class="c"># def degenerate_grad_like(x, k):</span>
<span class="c">#    R&quot;&quot;&quot;</span>
<span class="c">#    degenerate_grad_like(x, k)</span>
<span class="c">#</span>
<span class="c">#    Degenerate gradient log-likelihood.</span>
<span class="c">#</span>
<span class="c">#    .. math::</span>
<span class="c">#        f(x \mid k) = \left\{ \begin{matrix} 1 \text{ if } x = k \\ 0 \text{ if } x \ne k\end{matrix} \right.</span>
<span class="c">#</span>
<span class="c">#    :Parameters:</span>
<span class="c">#      - `x` : Input value.</span>
<span class="c">#      - `k` : Degenerate value.</span>
<span class="c">#    &quot;&quot;&quot;</span>
<span class="c">#    return np.zeros(np.size(x))*k</span>

<span class="c"># Dirichlet----------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rdirichlet</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Dirichlet random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">rgamma</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">gammas</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">gammas</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">gammas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">gammas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.</span>


<span class="k">def</span> <span class="nf">dirichlet_expval</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Dirichlet distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">theta</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>


<div class="viewcode-block" id="dirichlet_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.dirichlet_like">[docs]</a><span class="k">def</span> <span class="nf">dirichlet_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Dirichlet log-likelihood.</span>

<span class="sd">    This is a multivariate continuous distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(\mathbf{x}) = \frac{\Gamma(\sum_{i=1}^k \theta_i)}{\prod \Gamma(\theta_i)}\prod_{i=1}^{k-1} x_i^{\theta_i - 1}</span>
<span class="sd">        \cdot\left(1-\sum_{i=1}^{k-1}x_i\right)^\theta_k</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      x : (n, k-1) array</span>
<span class="sd">        Array of shape (n, k-1) where `n` is the number of samples</span>
<span class="sd">        and `k` the dimension.</span>
<span class="sd">        :math:`0 &lt; x_i &lt; 1`,  :math:`\sum_{i=1}^{k-1} x_i &lt; 1`</span>
<span class="sd">      theta : array</span>
<span class="sd">        An (n,k) or (1,k) array &gt; 0.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Only the first `k-1` elements of `x` are expected. Can be used</span>
<span class="sd">        as a parent of Multinomial and Categorical nevertheless.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">theta</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;The dimension of x in dirichlet_like must be k-1.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>

<span class="c"># Exponential----------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rexponential</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Exponential random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">exponential_expval</span><span class="p">(</span><span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of exponential distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">beta</span>


<div class="viewcode-block" id="exponential_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.exponential_like">[docs]</a><span class="k">def</span> <span class="nf">exponential_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Exponential log-likelihood.</span>

<span class="sd">    The exponential distribution is a special case of the gamma distribution</span>
<span class="sd">    with alpha=1. It often describes the time until an event.</span>

<span class="sd">    .. math:: f(x \mid \beta) = \beta e^{-\beta x}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x &gt; 0</span>
<span class="sd">      - `beta` : Rate parameter (beta &gt; 0).</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X) = 1/\beta`</span>
<span class="sd">      - :math:`Var(X) = 1/\beta^2`</span>
<span class="sd">      - PyMC&#39;s beta is named &#39;lambda&#39; by Wikipedia, SciPy, Wolfram MathWorld and other sources.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</div>
<span class="n">exponential_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">beta</span><span class="p">),</span>
                         <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_beta</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">beta</span><span class="p">)}</span>

<span class="c"># Exponentiated Weibull-----------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rexponweib</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random exponentiated Weibull variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">exponweib_ppf</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loc</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">scale</span>


<span class="k">def</span> <span class="nf">exponweib_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
    <span class="c"># Not sure how we can do this, since the first moment is only</span>
    <span class="c"># tractable at particular values of k</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s">&#39;exponweib_expval has not been implemented yet.&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="exponweib_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.exponweib_like">[docs]</a><span class="k">def</span> <span class="nf">exponweib_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Exponentiated Weibull log-likelihood.</span>

<span class="sd">    The exponentiated Weibull distribution is a generalization of the Weibull</span>
<span class="sd">    family. Its value lies in being able to model monotone and non-monotone</span>
<span class="sd">    failure rates.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha,k,loc,scale)  &amp; = \frac{\alpha k}{scale} (1-e^{-z^k})^{\alpha-1} e^{-z^k} z^{k-1} \\</span>
<span class="sd">        z &amp; = \frac{x-loc}{scale}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x &gt; 0</span>
<span class="sd">      - `alpha` : Shape parameter</span>
<span class="sd">      - `k` : k &gt; 0</span>
<span class="sd">      - `loc` : Location parameter</span>
<span class="sd">      - `scale` : Scale parameter (scale &gt; 0).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">exponweib</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
</div>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">commented out because tests fail</span>
<span class="sd">exponweib_grad_like = {&#39;value&#39; : flib.exponweib_gx,</span>
<span class="sd">                   &#39;alpha&#39; : flib.exponweib_ga,</span>
<span class="sd">                   &#39;k&#39; : flib.exponweib_gk,</span>
<span class="sd">                   &#39;loc&#39; : flib.exponweib_gl,</span>
<span class="sd">                   &#39;scale&#39; : flib.exponweib_gs}</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c"># Gamma----------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rgamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random gamma variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gamma_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of gamma distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">beta</span>


<div class="viewcode-block" id="gamma_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.gamma_like">[docs]</a><span class="k">def</span> <span class="nf">gamma_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Gamma log-likelihood.</span>

<span class="sd">    Represents the sum of alpha exponentially distributed random variables, each</span>
<span class="sd">    of which has mean beta.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{\beta^{\alpha}x^{\alpha-1}e^{-\beta x}}{\Gamma(\alpha)}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : math:`x \ge 0`</span>
<span class="sd">      - `alpha` : Shape parameter (alpha &gt; 0).</span>
<span class="sd">      - `beta` : Rate parameter (beta &gt; 0).</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(X) = \frac{\alpha}{\beta}`</span>
<span class="sd">       - :math:`Var(X) = \frac{\alpha}{\beta^2}`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

</div>
<span class="n">gamma_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_x</span><span class="p">,</span>
                   <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_alpha</span><span class="p">,</span>
                   <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_beta</span><span class="p">}</span>

<span class="c"># GEV Generalized Extreme Value ------------------------</span>
<span class="c"># Modify parameterization -&gt; Hosking (kappa, xi, alpha)</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rgev</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random generalized extreme value (GEV) variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">gev_ppf</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>


<span class="k">def</span> <span class="nf">gev_expval</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of generalized extreme value distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="p">(</span><span class="n">sigma</span> <span class="o">/</span> <span class="n">xi</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">sigma</span> <span class="o">/</span> <span class="n">xi</span><span class="p">)</span> <span class="o">*</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamfun</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">xi</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gev_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Generalized Extreme Value log-likelihood</span>

<span class="sd">    .. math::</span>
<span class="sd">        pdf(x \mid \xi,\mu,\sigma) = \frac{1}{\sigma}(1 + \xi \left[\frac{x-\mu}{\sigma}\right])^{-1/\xi-1}\exp{-(1+\xi \left[\frac{x-\mu}{\sigma}\right])^{-1/\xi}}</span>

<span class="sd">    .. math::</span>
<span class="sd">        \sigma &amp; &gt; 0,\\</span>
<span class="sd">        x &amp; &gt; \mu-\sigma/\xi \text{ if } \xi &gt; 0,\\</span>
<span class="sd">        x &amp; &lt; \mu-\sigma/\xi \text{ if } \xi &lt; 0\\</span>
<span class="sd">        x &amp; \in [-\infty,\infty] \text{ if } \xi = 0</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gev</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<span class="c"># Geometric----------------------------------------------</span>
<span class="c"># Changed the return value</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rgeometric</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random geometric variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">geometric_expval</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of geometric distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">p</span>


<div class="viewcode-block" id="geometric_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.geometric_like">[docs]</a><span class="k">def</span> <span class="nf">geometric_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Geometric log-likelihood. The probability that the first success in a</span>
<span class="sd">    sequence of Bernoulli trials occurs on the x&#39;th trial.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid p) = p(1-p)^{x-1}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] Number of trials before first success (x &gt; 0).</span>
<span class="sd">      - `p` : Probability of success on an individual trial, :math:`p \in [0,1]`</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X)=1/p`</span>
<span class="sd">      - :math:`Var(X)=\frac{1-p}{p^2}`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</div>
<span class="n">geometric_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">geometric_gp</span><span class="p">}</span>

<span class="c"># Half Cauchy----------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rhalf_cauchy</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns half-Cauchy random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tan</span><span class="p">(</span><span class="n">pi</span> <span class="o">*</span> <span class="n">random_number</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">-</span> <span class="n">pi</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">half_cauchy_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of cauchy distribution is undefined.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">inf</span>

<span class="c"># In wikipedia, the arguments name are k, x0.</span>


<div class="viewcode-block" id="half_cauchy_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.half_cauchy_like">[docs]</a><span class="k">def</span> <span class="nf">half_cauchy_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Half-Cauchy log-likelihood. Simply the absolute value of Cauchy.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{2}{\pi \beta [1 + (\frac{x-\alpha}{\beta})^2]}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `alpha` : Location parameter.</span>
<span class="sd">      - `beta` : Scale parameter (beta &gt; 0).</span>

<span class="sd">    .. note::</span>
<span class="sd">      - x must be non-negative.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">inf</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">cauchy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c"># Half-normal----------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rhalf_normal</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random half-normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">tau</span><span class="p">),</span> <span class="n">size</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">half_normal_expval</span><span class="p">(</span><span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of half normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tau</span><span class="p">))</span>


<div class="viewcode-block" id="half_normal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.half_normal_like">[docs]</a><span class="k">def</span> <span class="nf">half_normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Half-normal log-likelihood, a normal distribution with mean 0 limited</span>
<span class="sd">    to the domain :math:`x \in [0, \infty)`.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \tau) = \sqrt{\frac{2\tau}{\pi}}\exp\left\{ {\frac{-x^2 \tau}{2}}\right\}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : :math:`x \ge 0`</span>
<span class="sd">      - `tau` : tau &gt; 0</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">hnormal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
</div>
<span class="n">half_normal_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">hnormal_gradx</span><span class="p">,</span>
                         <span class="s">&#39;tau&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">hnormal_gradtau</span><span class="p">}</span>

<span class="c"># Hypergeometric----------------------------------------------</span>


<span class="k">def</span> <span class="nf">rhypergeometric</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns hypergeometric random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="n">N</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">hypergeometric</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">N</span> <span class="o">-</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">hypergeometric_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of hypergeometric distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">m</span> <span class="o">/</span> <span class="n">N</span>


<div class="viewcode-block" id="hypergeometric_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.hypergeometric_like">[docs]</a><span class="k">def</span> <span class="nf">hypergeometric_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Hypergeometric log-likelihood.</span>

<span class="sd">    Discrete probability distribution that describes the number of successes in</span>
<span class="sd">    a sequence of draws from a finite population without replacement.</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x \mid n, m, N) = \frac{\left({ \begin{array}{c} {m} \\ {x} \\</span>
<span class="sd">        \end{array} }\right)\left({ \begin{array}{c} {N-m} \\ {n-x} \\</span>
<span class="sd">        \end{array}}\right)}{\left({ \begin{array}{c} {N} \\ {n} \\</span>
<span class="sd">        \end{array}}\right)}</span>


<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] Number of successes in a sample drawn from a population.</span>
<span class="sd">      - `n` : [int] Size of sample drawn from the population.</span>
<span class="sd">      - `m` : [int] Number of successes in the population.</span>
<span class="sd">      - `N` : [int] Total number of units in the population.</span>

<span class="sd">    .. note::</span>

<span class="sd">        :math:`E(X) = \frac{n n}{N}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">hyperg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="c"># Inverse gamma----------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rinverse_gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random inverse gamma variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">inverse_gamma_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of inverse gamma distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span>


<div class="viewcode-block" id="inverse_gamma_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.inverse_gamma_like">[docs]</a><span class="k">def</span> <span class="nf">inverse_gamma_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Inverse gamma log-likelihood, the reciprocal of the gamma distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{-\alpha - 1} \exp\left(\frac{-\beta}{x}\right)</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x &gt; 0</span>
<span class="sd">      - `alpha` : Shape parameter (alpha &gt; 0).</span>
<span class="sd">      - `beta` : Scale parameter (beta &gt; 0).</span>

<span class="sd">    .. note::</span>

<span class="sd">       :math:`E(X)=\frac{\beta}{\alpha-1}`  for :math:`\alpha &gt; 1`</span>
<span class="sd">       :math:`Var(X)=\frac{\beta^2}{(\alpha-1)^2(\alpha-2)}`  for :math:`\alpha &gt; 2`</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">igamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</div>
<span class="n">inverse_gamma_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">igamma_grad_x</span><span class="p">,</span>
                           <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">igamma_grad_alpha</span><span class="p">,</span>
                           <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">igamma_grad_beta</span><span class="p">}</span>

<span class="c"># Inverse Wishart---------------------------------------------------</span>

<span class="c"># def rinverse_wishart(n, C):</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c">#     Return an inverse Wishart random matrix.</span>
<span class="c">#</span>
<span class="c">#     :Parameters:</span>
<span class="c">#       - `n` : [int] Degrees of freedom (n &gt; 0).</span>
<span class="c">#       - `C` : Symmetric and positive definite scale matrix</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c">#     wi = rwishart(n, np.asmatrix(C).I).I</span>
<span class="c">#     flib.symmetrize(wi)</span>
<span class="c">#     return wi</span>
<span class="c">#</span>
<span class="c"># def inverse_wishart_expval(n, C):</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c">#     Expected value of inverse Wishart distribution.</span>
<span class="c">#</span>
<span class="c">#     :Parameters:</span>
<span class="c">#       - `n` : [int] Degrees of freedom (n &gt; 0).</span>
<span class="c">#       - `C` : Symmetric and positive definite scale matrix</span>
<span class="c">#</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c">#     return np.asarray(C)/(n-len(C)-1)</span>
<span class="c">#</span>
<span class="c"># def inverse_wishart_like(X, n, C):</span>
<span class="c">#     R&quot;&quot;&quot;</span>
<span class="c">#     Inverse Wishart log-likelihood. The inverse Wishart distribution</span>
<span class="c">#     is the conjugate prior for the covariance matrix of a multivariate</span>
<span class="c">#     normal distribution.</span>
<span class="c">#</span>
<span class="c">#     .. math::</span>
<span class="c">#         f(X \mid n, T) = \frac{{\mid T \mid}^{n/2}{\mid X</span>
<span class="c">#         \mid}^{-(n+k+1)/2} \exp\left\{ -\frac{1}{2} Tr(TX^{-1})</span>
<span class="c">#         \right\}}{2^{nk/2} \Gamma_p(n/2)}</span>
<span class="c">#</span>
<span class="c">#     where :math:`k` is the rank of X.</span>
<span class="c">#</span>
<span class="c">#     :Parameters:</span>
<span class="c">#       - `X` : Symmetric, positive definite matrix.</span>
<span class="c">#       - `n` : [int] Degrees of freedom (n &gt; 0).</span>
<span class="c">#       - `C` : Symmetric and positive definite scale matrix</span>
<span class="c">#</span>
<span class="c">#     .. note::</span>
<span class="c">#        Step method MatrixMetropolis will preserve the symmetry of</span>
<span class="c">#        Wishart variables.</span>
<span class="c">#</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c">#     return flib.blas_wishart(X.I, n, C.I)</span>

<span class="c"># Double exponential (Laplace)--------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rlaplace</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Laplace (double exponential) random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">u</span><span class="p">))</span> <span class="o">/</span> <span class="n">tau</span>

<span class="n">rdexponential</span> <span class="o">=</span> <span class="n">rlaplace</span>


<span class="k">def</span> <span class="nf">laplace_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Laplace (double exponential) distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>

<span class="n">dexponential_expval</span> <span class="o">=</span> <span class="n">laplace_expval</span>


<div class="viewcode-block" id="laplace_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.laplace_like">[docs]</a><span class="k">def</span> <span class="nf">laplace_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Laplace (double exponential) log-likelihood.</span>

<span class="sd">    The Laplace (or double exponential) distribution describes the</span>
<span class="sd">    difference between two independent, identically distributed exponential</span>
<span class="sd">    events. It is often used as a heavier-tailed alternative to the normal.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \tau) = \frac{\tau}{2}e^{-\tau |x-\mu|}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : :math:`-\infty &lt; x &lt; \infty`</span>
<span class="sd">      - `mu` : Location parameter :math:`-\infty &lt; mu &lt; \infty`</span>
<span class="sd">      - `tau` : Scale parameter :math:`\tau &gt; 0`</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X) = \mu`</span>
<span class="sd">      - :math:`Var(X) = \frac{2}{\tau^2}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span> <span class="o">-</span> \
        <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</div>
<span class="n">laplace_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_x</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span>
                     <span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="o">-</span><span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_x</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span>
                     <span class="s">&#39;tau&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">gamma_grad_beta</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="p">)}</span>


<span class="n">dexponential_like</span> <span class="o">=</span> <span class="n">laplace_like</span>
<span class="n">dexponential_grad_like</span> <span class="o">=</span> <span class="n">laplace_grad_like</span>

<span class="c"># Logistic-----------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rlogistic</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logistic random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">u</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">u</span><span class="p">))</span> <span class="o">/</span> <span class="n">tau</span>


<span class="k">def</span> <span class="nf">logistic_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of logistic distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="logistic_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.logistic_like">[docs]</a><span class="k">def</span> <span class="nf">logistic_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Logistic log-likelihood.</span>

<span class="sd">    The logistic distribution is often used as a growth model; for example,</span>
<span class="sd">    populations, markets. Resembles a heavy-tailed normal distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, tau) = \frac{\tau \exp(-\tau[x-\mu])}{[1 + \exp(-\tau[x-\mu])]^2}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : :math:`-\infty &lt; x &lt; \infty`</span>
<span class="sd">      - `mu` : Location parameter :math:`-\infty &lt; mu &lt; \infty`</span>
<span class="sd">      - `tau` : Scale parameter (tau &gt; 0)</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(X) = \mu`</span>
<span class="sd">      - :math:`Var(X) = \frac{\pi^2}{3\tau^2}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">logistic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>


<span class="c"># Lognormal----------------------------------------------</span></div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rlognormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return random lognormal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">tau</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">lognormal_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of log-normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu</span> <span class="o">+</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">tau</span><span class="p">)</span>


<div class="viewcode-block" id="lognormal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.lognormal_like">[docs]</a><span class="k">def</span> <span class="nf">lognormal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Log-normal log-likelihood.</span>

<span class="sd">    Distribution of any random variable whose logarithm is normally</span>
<span class="sd">    distributed. A variable might be modeled as log-normal if it can be thought</span>
<span class="sd">    of as the multiplicative product of many small independent factors.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \tau) = \sqrt{\frac{\tau}{2\pi}}\frac{</span>
<span class="sd">        \exp\left\{ -\frac{\tau}{2} (\ln(x)-\mu)^2 \right\}}{x}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x &gt; 0</span>
<span class="sd">      - `mu` : Location parameter.</span>
<span class="sd">      - `tau` : Scale parameter (tau &gt; 0).</span>

<span class="sd">    .. note::</span>

<span class="sd">       :math:`E(X)=e^{\mu+\frac{1}{2\tau}}`</span>
<span class="sd">       :math:`Var(X)=(e^{1/\tau}-1)e^{2\mu+\frac{1}{\tau}}`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
</div>
<span class="n">lognormal_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">lognormal_gradx</span><span class="p">,</span>
                       <span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">lognormal_gradmu</span><span class="p">,</span>
                       <span class="s">&#39;tau&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">lognormal_gradtau</span><span class="p">}</span>


<span class="c"># Multinomial----------------------------------------------</span>
<span class="c">#@randomwrap</span>
<span class="k">def</span> <span class="nf">rmultinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random multinomial variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># Leaving size=None as the default means return value is 1d array</span>
    <span class="c"># if not specified-- nicer.</span>

    <span class="c"># Single value for p:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

    <span class="c"># Multiple values for p:</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">multinomial_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of multinomial distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">pr</span> <span class="o">*</span> <span class="n">n</span> <span class="k">for</span> <span class="n">pr</span> <span class="ow">in</span> <span class="n">p</span><span class="p">])</span>


<div class="viewcode-block" id="multinomial_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.multinomial_like">[docs]</a><span class="k">def</span> <span class="nf">multinomial_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Multinomial log-likelihood.</span>

<span class="sd">    Generalization of the binomial</span>
<span class="sd">    distribution, but instead of each trial resulting in &quot;success&quot; or</span>
<span class="sd">    &quot;failure&quot;, each one results in exactly one of some fixed finite number k</span>
<span class="sd">    of possible outcomes over n independent trials. &#39;x[i]&#39; indicates the number</span>
<span class="sd">    of times outcome number i was observed over the n trials.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid n, p) = \frac{n!}{\prod_{i=1}^k x_i!} \prod_{i=1}^k p_i^{x_i}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      x : (ns, k) int</span>
<span class="sd">          Random variable indicating the number of time outcome i is</span>
<span class="sd">          observed. :math:`\sum_{i=1}^k x_i=n`, :math:`x_i \ge 0`.</span>
<span class="sd">      n : int</span>
<span class="sd">          Number of trials.</span>
<span class="sd">      p : (k,)</span>
<span class="sd">          Probability of each one of the different outcomes.</span>
<span class="sd">          :math:`\sum_{i=1}^k p_i = 1)`, :math:`p_i \ge 0`.</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(X_i)=n p_i`</span>
<span class="sd">       - :math:`Var(X_i)=n p_i(1-p_i)`</span>
<span class="sd">       - :math:`Cov(X_i,X_j) = -n p_i p_j`</span>
<span class="sd">       - If :math:`\sum_i p_i &lt; 0.999999` a log-likelihood value of -inf</span>
<span class="sd">       will be returned.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># flib expects 2d arguments. Do we still want to support multiple p</span>
    <span class="c"># values along realizations ?</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c"># Multivariate hypergeometric------------------------------</span>

</div>
<span class="k">def</span> <span class="nf">rmultivariate_hypergeometric</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random multivariate hypergeometric variates.</span>

<span class="sd">    Parameters:</span>
<span class="sd">      - `n` : Number of draws.</span>
<span class="sd">      - `m` : Number of items in each categoy.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">urn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">size</span><span class="p">:</span>
        <span class="n">draw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">urn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">urn</span><span class="p">))[:</span><span class="n">n</span><span class="p">]]</span>
                         <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span>

        <span class="n">r</span> <span class="o">=</span> <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">draw</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="p">))]</span>
             <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">draw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">urn</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">urn</span><span class="p">))[:</span><span class="n">n</span><span class="p">]])</span>

        <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">draw</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">multivariate_hypergeometric_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of multivariate hypergeometric distribution.</span>

<span class="sd">    Parameters:</span>
<span class="sd">      - `n` : Number of draws.</span>
<span class="sd">      - `m` : Number of items in each categoy.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">m</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>


<div class="viewcode-block" id="multivariate_hypergeometric_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.multivariate_hypergeometric_like">[docs]</a><span class="k">def</span> <span class="nf">multivariate_hypergeometric_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Multivariate hypergeometric log-likelihood</span>

<span class="sd">    Describes the probability of drawing x[i] elements of the ith category,</span>
<span class="sd">    when the number of items in each category is given by m.</span>

<span class="sd">    .. math::</span>
<span class="sd">        \frac{\prod_i \left({ \begin{array}{c} {m_i} \\ {x_i} \\</span>
<span class="sd">        \end{array}}\right)}{\left({ \begin{array}{c} {N} \\ {n} \\</span>
<span class="sd">        \end{array}}\right)}</span>


<span class="sd">    where :math:`N = \sum_i m_i` and :math:`n = \sum_i x_i`.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int sequence] Number of draws from each category, (x &lt; m).</span>
<span class="sd">      - `m` : [int sequence] Number of items in each categoy.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">mvhyperg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>


<span class="c"># Multivariate normal--------------------------------------</span></div>
<span class="k">def</span> <span class="nf">rmv_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random multivariate normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">mu_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">mu_size</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">flib</span><span class="o">.</span><span class="n">dtrsm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="s">&#39;T&#39;</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">mu</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="s">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,)</span>
        <span class="n">tot_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">tot_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">mu_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">tot_size</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">flib</span><span class="o">.</span><span class="n">dtrsm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="s">&#39;T&#39;</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">mu</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">mu_size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">mv_normal_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of multivariate normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="mv_normal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.mv_normal_like">[docs]</a><span class="k">def</span> <span class="nf">mv_normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Multivariate normal log-likelihood</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \pi, T) = \frac{|T|^{1/2}}{(2\pi)^{1/2}} \exp\left\{ -\frac{1}{2} (x-\mu)^{\prime}T(x-\mu) \right\}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : (n,k)</span>
<span class="sd">      - `mu` : (k) Location parameter sequence.</span>
<span class="sd">      - `Tau` : (k,k) Positive definite precision matrix.</span>

<span class="sd">    .. seealso:: :func:`mv_normal_chol_like`, :func:`mv_normal_cov_like`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># TODO: Vectorize in Fortran</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">flib</span><span class="o">.</span><span class="n">prec_mvnorm</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">prec_mvnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

<span class="c"># Multivariate normal, parametrized with covariance---------------------------</span>

</div>
<span class="k">def</span> <span class="nf">rmv_normal_cov</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random multivariate normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mu_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mu_size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">mu_size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">mv_normal_cov_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of multivariate normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="mv_normal_cov_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.mv_normal_cov_like">[docs]</a><span class="k">def</span> <span class="nf">mv_normal_cov_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Multivariate normal log-likelihood parameterized by a covariance</span>
<span class="sd">    matrix.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \pi, C) = \frac{1}{(2\pi|C|)^{1/2}} \exp\left\{ -\frac{1}{2} (x-\mu)^{\prime}C^{-1}(x-\mu) \right\}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : (n,k)</span>
<span class="sd">      - `mu` : (k) Location parameter.</span>
<span class="sd">      - `C` : (k,k) Positive definite covariance matrix.</span>

<span class="sd">    .. seealso:: :func:`mv_normal_like`, :func:`mv_normal_chol_like`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># TODO: Vectorize in Fortran</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">flib</span><span class="o">.</span><span class="n">cov_mvnorm</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">cov_mvnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>


<span class="c"># Multivariate normal, parametrized with Cholesky factorization.----------</span></div>
<span class="k">def</span> <span class="nf">rmv_normal_chol</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sig</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random multivariate normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mu_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">mu_size</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">flib</span><span class="o">.</span><span class="n">dtrmm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="s">&#39;N&#39;</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">mu</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="s">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,)</span>
        <span class="n">tot_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">tot_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">mu_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">tot_size</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">flib</span><span class="o">.</span><span class="n">dtrmm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="s">&#39;N&#39;</span><span class="p">,</span> <span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">mu</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">mu_size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">mv_normal_chol_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of multivariate normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="mv_normal_chol_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.mv_normal_chol_like">[docs]</a><span class="k">def</span> <span class="nf">mv_normal_chol_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Multivariate normal log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \pi, \sigma) = \frac{1}{(2\pi)^{1/2}|\sigma|)} \exp\left\{ -\frac{1}{2} (x-\mu)^{\prime}(\sigma \sigma^{\prime})^{-1}(x-\mu) \right\}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : (n,k)</span>
<span class="sd">      - `mu` : (k) Location parameter.</span>
<span class="sd">      - `sigma` : (k,k) Lower triangular matrix.</span>

<span class="sd">    .. seealso:: :func:`mv_normal_like`, :func:`mv_normal_cov_like`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># TODO: Vectorize in Fortran</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">flib</span><span class="o">.</span><span class="n">chol_mvnorm</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">chol_mvnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>


<span class="c"># Negative binomial----------------------------------------</span></div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rnegative_binomial</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random negative binomial variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># Using gamma-poisson mixture rather than numpy directly</span>
    <span class="c"># because numpy apparently rounds</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">pois_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">mu</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">pois_mu</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="c"># return np.random.negative_binomial(alpha, alpha / (mu + alpha), size)</span>


<span class="k">def</span> <span class="nf">negative_binomial_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of negative binomial distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="negative_binomial_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.negative_binomial_like">[docs]</a><span class="k">def</span> <span class="nf">negative_binomial_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Negative binomial log-likelihood.</span>

<span class="sd">    The negative binomial</span>
<span class="sd">    distribution describes a Poisson random variable whose rate</span>
<span class="sd">    parameter is gamma distributed. PyMC&#39;s chosen parameterization is</span>
<span class="sd">    based on this mixture interpretation.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \alpha) = \frac{\Gamma(x+\alpha)}{x! \Gamma(\alpha)} (\alpha/(\mu+\alpha))^\alpha (\mu/(\mu+\alpha))^x</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : x = 0,1,2,...</span>
<span class="sd">      - `mu` : mu &gt; 0</span>
<span class="sd">      - `alpha` : alpha &gt; 0</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E[x]=\mu`</span>
<span class="sd">      - In Wikipedia&#39;s parameterization,</span>
<span class="sd">        :math:`r=\alpha`</span>
<span class="sd">        :math:`p=\alpha/(\mu+\alpha)`</span>
<span class="sd">        :math:`\mu=rp/(1-p)`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1e10</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1e10</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="c"># Return Poisson when alpha gets very large</span>
            <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>

        <span class="c"># Split big and small dispersion values</span>
        <span class="n">big</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1e10</span>
        <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">big</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="n">big</span><span class="p">])</span> <span class="o">+</span> <span class="n">flib</span><span class="o">.</span><span class="n">negbin2</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">big</span> <span class="o">-</span> <span class="bp">True</span><span class="p">],</span>
                                                            <span class="n">mu</span><span class="p">[</span><span class="n">big</span> <span class="o">-</span> <span class="bp">True</span><span class="p">],</span> <span class="n">alpha</span><span class="p">[</span><span class="n">big</span> <span class="o">-</span> <span class="bp">True</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">negbin2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</div>
<span class="n">negative_binomial_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">negbin2_gmu</span><span class="p">,</span>
                               <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">negbin2_ga</span><span class="p">}</span>

<span class="c"># Normal---------------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rnormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">normal_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="normal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.normal_like">[docs]</a><span class="k">def</span> <span class="nf">normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Normal log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \tau) = \sqrt{\frac{\tau}{2\pi}} \exp\left\{ -\frac{\tau}{2} (x-\mu)^2 \right\}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `mu` : Mean of the distribution.</span>
<span class="sd">      - `tau` : Precision of the distribution, which corresponds to</span>
<span class="sd">        :math:`1/\sigma^2` (tau &gt; 0).</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(X) = \mu`</span>
<span class="sd">       - :math:`Var(X) = 1/\tau`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># try:</span>
    <span class="c">#     constrain(tau, lower=0)</span>
    <span class="c"># except ZeroProbability:</span>
    <span class="c">#     return -np.Inf</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

</div>
<span class="k">def</span> <span class="nf">t_normal_grad_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">normal_grad_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">t_normal_grad_mu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">normal_grad_mu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">t_normal_grad_tau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">normal_grad_tau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

<span class="n">normal_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">t_normal_grad_x</span><span class="p">,</span>
                    <span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="n">t_normal_grad_mu</span><span class="p">,</span>
                    <span class="s">&#39;tau&#39;</span><span class="p">:</span> <span class="n">t_normal_grad_tau</span><span class="p">}</span>

<span class="c"># normal_grad_like = {&#39;x&#39; : flib.normal_grad_x,</span>
<span class="c">#             &#39;mu&#39; : flib.normal_grad_mu,</span>
<span class="c">#             &#39;tau&#39; : flib.normal_grad_tau}</span>

<span class="c"># von Mises--------------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rvon_mises</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random von Mises variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># TODO: Just return straight from numpy after release 1.3</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">mtrand</span><span class="o">.</span><span class="n">vonmises</span><span class="p">(</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>


<span class="k">def</span> <span class="nf">von_mises_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of von Mises distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="von_mises_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.von_mises_like">[docs]</a><span class="k">def</span> <span class="nf">von_mises_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    von Mises log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, k) = \frac{e^{k \cos(x - \mu)}}{2 \pi I_0(k)}</span>

<span class="sd">    where `I_0` is the modified Bessel function of order 0.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `mu` : Mean of the distribution.</span>
<span class="sd">      - `kappa` : Dispersion of the distribution</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(X) = \mu`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">vonmises</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)</span>

<span class="c"># Pareto---------------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rpareto</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random Pareto variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="n">random_number</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pareto_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Pareto distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inf</span>
    <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>


<div class="viewcode-block" id="pareto_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.pareto_like">[docs]</a><span class="k">def</span> <span class="nf">pareto_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Pareto log-likelihood. The Pareto is a continuous, positive</span>
<span class="sd">    probability distribution with two parameters. It is often used</span>
<span class="sd">    to characterize wealth distribution, or other examples of the</span>
<span class="sd">    80/20 rule.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, m) = \frac{\alpha m^{\alpha}}{x^{\alpha+1}}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data (x &gt; m)</span>
<span class="sd">      - `alpha` : Shape parameter (alpha&gt;0)</span>
<span class="sd">      - `m` : Scale parameter (m&gt;0)</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(x)=\frac{\alpha m}{\alpha-1} if \alpha &gt; 1`</span>
<span class="sd">       - :math:`Var(x)=\frac{m^2 \alpha}{(\alpha-1)^2(\alpha-2)} if \alpha &gt; 2`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">pareto</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="c"># Truncated Pareto---------------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rtruncated_pareto</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random bounded Pareto variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">random_number</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="n">b</span> <span class="o">**</span> <span class="n">alpha</span> <span class="o">-</span> <span class="n">u</span> <span class="o">*</span> <span class="n">m</span> <span class="o">**</span> <span class="n">alpha</span> <span class="o">-</span> <span class="n">b</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span>
            <span class="p">(</span><span class="n">b</span> <span class="o">**</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">m</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">))</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">truncated_pareto_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of truncated Pareto distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inf</span>
    <span class="n">part1</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">b</span><span class="p">)</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">part2</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">part3</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">**</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">b</span> <span class="o">**</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">part1</span> <span class="o">*</span> <span class="n">part2</span> <span class="o">*</span> <span class="n">part3</span>


<div class="viewcode-block" id="truncated_pareto_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.truncated_pareto_like">[docs]</a><span class="k">def</span> <span class="nf">truncated_pareto_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Truncated Pareto log-likelihood. The Pareto is a continuous, positive</span>
<span class="sd">    probability distribution with two parameters. It is often used</span>
<span class="sd">    to characterize wealth distribution, or other examples of the</span>
<span class="sd">    80/20 rule.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, m, b) = \frac{\alpha m^{\alpha} x^{-\alpha}}{1-(m/b)**{\alpha}}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data (x &gt; m)</span>
<span class="sd">      - `alpha` : Shape parameter (alpha&gt;0)</span>
<span class="sd">      - `m` : Scale parameter (m&gt;0)</span>
<span class="sd">      - `b` : Upper bound (b&gt;m)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">truncated_pareto</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c"># Poisson--------------------------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rpoisson</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random poisson variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">poisson_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Poisson distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">mu</span>


<div class="viewcode-block" id="poisson_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.poisson_like">[docs]</a><span class="k">def</span> <span class="nf">poisson_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Poisson log-likelihood.</span>

<span class="sd">    The Poisson is a discrete probability</span>
<span class="sd">    distribution.  It is often used to model the number of events</span>
<span class="sd">    occurring in a fixed period of time when the times at which events</span>
<span class="sd">    occur are independent. The Poisson distribution can be derived as</span>
<span class="sd">    a limiting case of the binomial distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu) = \frac{e^{-\mu}\mu^x}{x!}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] :math:`x \in {0,1,2,...}`</span>
<span class="sd">      - `mu` : Expected number of occurrences during the given interval, :math:`\mu \geq 0`.</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(x)=\mu`</span>
<span class="sd">       - :math:`Var(x)=\mu`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
</div>
<span class="n">poisson_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">poisson_gmu</span><span class="p">}</span>

<span class="c"># Truncated Poisson--------------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rtruncated_poisson</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random truncated Poisson variates with minimum value k, generated</span>
<span class="sd">    using rejection sampling.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c"># Calculate m</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">mu</span><span class="p">))</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="c"># More than one mu</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">rtruncated_poisson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">mu</span><span class="p">)))])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">k</span> <span class="o">-=</span> <span class="mi">1</span>

    <span class="c"># Calculate constant for acceptance probability</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">flib</span><span class="o">.</span><span class="n">factln</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">flib</span><span class="o">.</span><span class="n">factln</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">m</span><span class="p">))</span>

    <span class="c"># Empty array to hold random variates</span>
    <span class="n">rvs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>

    <span class="n">total_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">size</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">while</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rvs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">total_size</span><span class="p">):</span>

        <span class="c"># Propose values by sampling from untruncated Poisson with mean mu + m</span>
        <span class="n">proposals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span>
            <span class="n">mu</span> <span class="o">+</span> <span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">total_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">m</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c"># Acceptance probability</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">C</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">flib</span><span class="o">.</span><span class="n">factln</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">-</span> <span class="n">flib</span><span class="o">.</span><span class="n">factln</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
                          <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">proposals</span><span class="p">])</span>
        <span class="n">a</span> <span class="o">*=</span> <span class="n">proposals</span> <span class="o">&gt;</span> <span class="n">k</span>

        <span class="c"># Uniform random variates</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">total_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>

        <span class="n">rvs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">proposals</span><span class="p">[</span><span class="n">u</span> <span class="o">&lt;</span> <span class="n">a</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">rvs</span><span class="p">[:</span><span class="n">total_size</span><span class="p">],</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">truncated_poisson_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of Poisson distribution truncated to be no smaller than k.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">mu</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">poiscdf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">mu</span><span class="p">))</span>


<div class="viewcode-block" id="truncated_poisson_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.truncated_poisson_like">[docs]</a><span class="k">def</span> <span class="nf">truncated_poisson_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Truncated Poisson log-likelihood.</span>

<span class="sd">    The Truncated Poisson is a</span>
<span class="sd">    discrete probability distribution that is arbitrarily truncated to</span>
<span class="sd">    be greater than some minimum value k. For example, zero-truncated</span>
<span class="sd">    Poisson distributions can be used to model counts that are</span>
<span class="sd">    constrained to be non-negative.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, k) = \frac{e^{-\mu}\mu^x}{x!(1-F(k|\mu))}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] :math:`x \in {0,1,2,...}`</span>
<span class="sd">      - `mu` : Expected number of occurrences during the given interval,</span>
<span class="sd">               :math:`\mu \geq 0`.</span>
<span class="sd">      - `k` : Truncation point representing the minimum allowable value.</span>

<span class="sd">    .. note::</span>
<span class="sd">       - :math:`E(x)=\frac{\mu}{1-F(k|\mu)}`</span>
<span class="sd">       - :math:`Var(x)=\frac{\mu}{1-F(k|\mu)}`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">trpoisson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</div>
<span class="n">truncated_poisson_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;mu&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">trpoisson_gmu</span><span class="p">}</span>

<span class="c"># Truncated normal distribution--------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rtruncated_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random truncated normal variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">b</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span>

    <span class="c"># Use the inverse CDF generation method.</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">mtrand</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">U</span> <span class="o">*</span> <span class="n">nb</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">U</span><span class="p">)</span> <span class="o">*</span> <span class="n">na</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">invcdf</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>

    <span class="c"># Unnormalize</span>
    <span class="k">return</span> <span class="n">R</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>

<span class="n">rtruncnorm</span> <span class="o">=</span> <span class="n">rtruncated_normal</span>


<span class="k">def</span> <span class="nf">truncated_normal_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Expected value of the truncated normal distribution.</span>

<span class="sd">    .. math::</span>
<span class="sd">       E(X) =\mu + \frac{\sigma(\varphi_1-\varphi_2)}{T}</span>


<span class="sd">    where</span>

<span class="sd">    .. math::</span>
<span class="sd">       T &amp; =\Phi\left(\frac{B-\mu}{\sigma}\right)-\Phi</span>
<span class="sd">       \left(\frac{A-\mu}{\sigma}\right)\text \\</span>
<span class="sd">       \varphi_1 &amp;=</span>
<span class="sd">       \varphi\left(\frac{A-\mu}{\sigma}\right) \\</span>
<span class="sd">       \varphi_2 &amp;=</span>
<span class="sd">       \varphi\left(\frac{B-\mu}{\sigma}\right) \\</span>

<span class="sd">    and :math:`\varphi = N(0,1)` and :math:`tau &amp; 1/sigma**2`.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `mu` : Mean of the distribution.</span>
<span class="sd">      - `tau` : Precision of the distribution, which corresponds to 1/sigma**2 (tau &gt; 0).</span>
<span class="sd">      - `a` : Left bound of the distribution.</span>
<span class="sd">      - `b` : Right bound of the distribution.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">phia</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">normal_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">))</span>
    <span class="n">phib</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">normal_like</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">Phia</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
        <span class="n">Phib</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Phib</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">b</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mu</span> <span class="o">+</span> <span class="p">(</span><span class="n">phia</span> <span class="o">-</span> <span class="n">phib</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">Phib</span> <span class="o">-</span> <span class="n">Phia</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">truncnorm_expval</span> <span class="o">=</span> <span class="n">truncated_normal_expval</span>


<div class="viewcode-block" id="truncated_normal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.truncated_normal_like">[docs]</a><span class="k">def</span> <span class="nf">truncated_normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Truncated normal log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \tau, a, b) = \frac{\phi(\frac{x-\mu}{\sigma})} {\Phi(\frac{b-\mu}{\sigma}) - \Phi(\frac{a-\mu}{\sigma})},</span>

<span class="sd">    where :math:`\sigma^2=1/\tau`, `\phi` is the standard normal PDF and `\Phi` is the standard normal CDF.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `mu` : Mean of the distribution.</span>
<span class="sd">      - `tau` : Precision of the distribution, which corresponds to 1/sigma**2 (tau &gt; 0).</span>
<span class="sd">      - `a` : Left bound of the distribution.</span>
<span class="sd">      - `b` : Right bound of the distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau</span><span class="p">)))</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">phi</span> <span class="o">=</span> <span class="n">normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
        <span class="n">lPhia</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">lPhib</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">normcdf</span><span class="p">((</span><span class="n">b</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_difference</span><span class="p">(</span><span class="n">lPhib</span><span class="p">,</span> <span class="n">lPhia</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="c"># d = np.log(Phib-Phia)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">Phi</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Phi</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">d</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Phi</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">Phi</span><span class="p">):</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">return</span> <span class="n">phi</span> <span class="o">-</span> <span class="n">Phi</span>
</div>
<span class="n">truncnorm_like</span> <span class="o">=</span> <span class="n">truncated_normal_like</span>

<span class="c"># Azzalini&#39;s skew-normal-----------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rskew_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">()):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Skew-normal random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">size_</span> <span class="o">=</span> <span class="n">size</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="n">len_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">size_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">rskewnorm</span><span class="p">(</span>
        <span class="n">len_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">len_</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">skew_normal_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expectation of skew-normal random variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">pi</span> <span class="o">/</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta</span>


<div class="viewcode-block" id="skew_normal_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.skew_normal_like">[docs]</a><span class="k">def</span> <span class="nf">skew_normal_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Azzalini&#39;s skew-normal log-likelihood</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \mu, \tau, \alpha) = 2 \Phi((x-\mu)\sqrt{\tau}\alpha) \phi(x,\mu,\tau)</span>

<span class="sd">    where :math:\Phi is the normal CDF and :math: \phi is the normal PDF.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `mu` : Mean of the distribution.</span>
<span class="sd">      - `tau` : Precision of the distribution (&gt; 0).</span>
<span class="sd">      - `alpha` : Shape parameter of the distribution.</span>

<span class="sd">    .. note::</span>
<span class="sd">      See http://azzalini.stat.unipd.it/SN/</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">sn_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>


<span class="c"># Student&#39;s t-----------------------------------</span></div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rt</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Student&#39;s t random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">rnormal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rchi2</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="n">nu</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">t_expval</span><span class="p">(</span><span class="n">nu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expectation of Student&#39;s t random variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">0</span>


<div class="viewcode-block" id="t_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.t_like">[docs]</a><span class="k">def</span> <span class="nf">t_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Student&#39;s T log-likelihood.</span>

<span class="sd">    Describes a zero-mean normal variable</span>
<span class="sd">    whose precision is gamma distributed. Alternatively, describes the</span>
<span class="sd">    mean of several zero-mean normal random variables divided by their</span>
<span class="sd">    sample standard deviation.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \nu) = \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2}) \sqrt{\nu\pi}} \left( 1 + \frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `nu` : Degrees of freedom.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>

<span class="c"># Non-central Student&#39;s t-----------------------------------</span>

</div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rnoncentral_t</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Non-central Student&#39;s t random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">rgamma</span><span class="p">(</span><span class="n">nu</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">nu</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">lam</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rnormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">noncentral_t_expval</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;noncentral_t_expval(mu, lam, nu)</span>

<span class="sd">    Expectation of non-central Student&#39;s t random variables. Only defined</span>
<span class="sd">    for nu&gt;1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">nu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mu</span>
    <span class="k">return</span> <span class="n">inf</span>


<div class="viewcode-block" id="noncentral_t_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.noncentral_t_like">[docs]</a><span class="k">def</span> <span class="nf">noncentral_t_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Non-central Student&#39;s T log-likelihood.</span>

<span class="sd">    Describes a normal variable whose precision is gamma distributed.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x|\mu,\lambda,\nu) = \frac{\Gamma(\frac{\nu +</span>
<span class="sd">        1}{2})}{\Gamma(\frac{\nu}{2})}</span>
<span class="sd">        \left(\frac{\lambda}{\pi\nu}\right)^{\frac{1}{2}}</span>
<span class="sd">        \left[1+\frac{\lambda(x-\mu)^2}{\nu}\right]^{-\frac{\nu+1}{2}}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : Input data.</span>
<span class="sd">      - `mu` : Location parameter.</span>
<span class="sd">      - `lambda` : Scale parameter.</span>
<span class="sd">      - `nu` : Degrees of freedom.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">nct</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>

</div>
<span class="k">def</span> <span class="nf">t_grad_setup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nu</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>

<span class="n">t_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">:</span> <span class="n">t_grad_setup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">flib</span><span class="o">.</span><span class="n">t_grad_x</span><span class="p">),</span>
               <span class="s">&#39;nu&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">:</span> <span class="n">t_grad_setup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">flib</span><span class="o">.</span><span class="n">t_grad_nu</span><span class="p">)}</span>


<span class="c"># DiscreteUniform--------------------------------------------------</span>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rdiscrete_uniform</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random discrete_uniform variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">discrete_uniform_expval</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of discrete_uniform distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">upper</span> <span class="o">-</span> <span class="n">lower</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span>


<div class="viewcode-block" id="discrete_uniform_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.discrete_uniform_like">[docs]</a><span class="k">def</span> <span class="nf">discrete_uniform_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Discrete uniform log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid lower, upper) = \frac{1}{upper-lower}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : [int] :math:`lower \leq x \leq upper`</span>
<span class="sd">      - `lower` : Lower limit.</span>
<span class="sd">      - `upper` : Upper limit (upper &gt; lower).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">duniform_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>


<span class="c"># Uniform--------------------------------------------------</span></div>
<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">runiform</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Random uniform variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">uniform_expval</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of uniform distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">upper</span> <span class="o">-</span> <span class="n">lower</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span>


<div class="viewcode-block" id="uniform_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.uniform_like">[docs]</a><span class="k">def</span> <span class="nf">uniform_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Uniform log-likelihood.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid lower, upper) = \frac{1}{upper-lower}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : :math:`lower \leq x \leq upper`</span>
<span class="sd">      - `lower` : Lower limit.</span>
<span class="sd">      - `upper` : Upper limit (upper &gt; lower).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">uniform_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
</div>
<span class="n">uniform_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">uniform_grad_x</span><span class="p">,</span>
                     <span class="s">&#39;lower&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">uniform_grad_l</span><span class="p">,</span>
                     <span class="s">&#39;upper&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">uniform_grad_u</span><span class="p">}</span>

<span class="c"># Weibull--------------------------------------------------</span>


<span class="nd">@randomwrap</span>
<span class="k">def</span> <span class="nf">rweibull</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Weibull random variates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">runiform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">tmp</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">weibull_expval</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of weibull distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">gammaln</span><span class="p">((</span><span class="n">alpha</span> <span class="o">+</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">))</span>


<div class="viewcode-block" id="weibull_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.weibull_like">[docs]</a><span class="k">def</span> <span class="nf">weibull_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Weibull log-likelihood</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(x \mid \alpha, \beta) = \frac{\alpha x^{\alpha - 1}</span>
<span class="sd">        \exp(-(\frac{x}{\beta})^{\alpha})}{\beta^\alpha}</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      - `x` : :math:`x \ge 0`</span>
<span class="sd">      - `alpha` : alpha &gt; 0</span>
<span class="sd">      - `beta` : beta &gt; 0</span>

<span class="sd">    .. note::</span>
<span class="sd">      - :math:`E(x)=\beta \Gamma(1+\frac{1}{\alpha})`</span>
<span class="sd">      - :math:`Var(x)=\beta^2 \Gamma(1+\frac{2}{\alpha} - \mu^2)`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">weibull</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</div>
<span class="n">weibull_grad_like</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;value&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">weibull_gx</span><span class="p">,</span>
                     <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">weibull_ga</span><span class="p">,</span>
                     <span class="s">&#39;beta&#39;</span><span class="p">:</span> <span class="n">flib</span><span class="o">.</span><span class="n">weibull_gb</span><span class="p">}</span>

<span class="c"># Wishart---------------------------------------------------</span>


<span class="k">def</span> <span class="nf">rwishart</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">Tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Wishart random matrix.</span>

<span class="sd">    Tau is the inverse of the &#39;covariance&#39; matrix :math:`C`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">Tau</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Tau</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;Wishart parameter n must be greater &#39;</span>
                         <span class="s">&#39;than size of matrix.&#39;</span><span class="p">)</span>
    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">chi_sqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">expand_triangular</span><span class="p">(</span><span class="n">chi_sqs</span><span class="p">,</span> <span class="n">norms</span><span class="p">)</span>

    <span class="n">flib</span><span class="o">.</span><span class="n">dtrsm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="n">uplo</span><span class="o">=</span><span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="n">transa</span><span class="o">=</span><span class="s">&#39;T&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asmatrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">flib</span><span class="o">.</span><span class="n">symmetrize</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w</span>


<span class="k">def</span> <span class="nf">wishart_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">Tau</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of wishart distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Tau</span><span class="o">.</span><span class="n">I</span><span class="p">)</span>


<div class="viewcode-block" id="wishart_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.wishart_like">[docs]</a><span class="k">def</span> <span class="nf">wishart_like</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">Tau</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    Wishart log-likelihood.</span>

<span class="sd">    The Wishart distribution is the probability</span>
<span class="sd">    distribution of the maximum-likelihood estimator (MLE) of the precision</span>
<span class="sd">    matrix of a multivariate normal distribution. If Tau=1, the distribution</span>
<span class="sd">    is identical to the chi-square distribution with n degrees of freedom.</span>

<span class="sd">    For an alternative parameterization based on :math:`C=T{-1}`, see</span>
<span class="sd">    `wishart_cov_like`.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(X \mid n, T) = \frac{{\mid T \mid}^{n/2}{\mid X \mid}^{(n-k-1)/2}}{2^{nk/2}</span>
<span class="sd">        \Gamma_p(n/2)} \exp\left\{ -\frac{1}{2} Tr(TX) \right\}</span>

<span class="sd">    where :math:`k` is the rank of X.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      X : matrix</span>
<span class="sd">        Symmetric, positive definite.</span>
<span class="sd">      n : int</span>
<span class="sd">        Degrees of freedom, &gt; 0.</span>
<span class="sd">      Tau : matrix</span>
<span class="sd">        Symmetric and positive definite</span>

<span class="sd">    .. note::</span>
<span class="sd">      Step method MatrixMetropolis will preserve the symmetry of Wishart variables.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">blas_wishart</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">Tau</span><span class="p">)</span>

<span class="c"># Wishart, parametrized by covariance ------------------------------------</span>

</div>
<span class="k">def</span> <span class="nf">rwishart_cov</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Wishart random matrix.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      n : int</span>
<span class="sd">        Degrees of freedom, &gt; 0.</span>
<span class="sd">      C : matrix</span>
<span class="sd">        Symmetric and positive definite</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># return rwishart(n, np.linalg.inv(C))</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">C</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c"># Need cholesky decomposition of precision matrix C^-1?</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&#39;Wishart parameter n must be greater &#39;</span>
                         <span class="s">&#39;than size of matrix.&#39;</span><span class="p">)</span>

    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">chi_sqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">flib</span><span class="o">.</span><span class="n">expand_triangular</span><span class="p">(</span><span class="n">chi_sqs</span><span class="p">,</span> <span class="n">norms</span><span class="p">)</span>

    <span class="n">flib</span><span class="o">.</span><span class="n">dtrmm_wrap</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="n">uplo</span><span class="o">=</span><span class="s">&#39;L&#39;</span><span class="p">,</span> <span class="n">transa</span><span class="o">=</span><span class="s">&#39;N&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asmatrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">flib</span><span class="o">.</span><span class="n">symmetrize</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w</span>


<span class="k">def</span> <span class="nf">wishart_cov_expval</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of wishart distribution.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      n : int</span>
<span class="sd">        Degrees of freedom, &gt; 0.</span>
<span class="sd">      C : matrix</span>
<span class="sd">        Symmetric and positive definite</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>


<div class="viewcode-block" id="wishart_cov_like"><a class="viewcode-back" href="../../distributions.html#pymc.distributions.wishart_cov_like">[docs]</a><span class="k">def</span> <span class="nf">wishart_cov_like</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">R&quot;&quot;&quot;</span>
<span class="sd">    wishart_like(X, n, C)</span>

<span class="sd">    Wishart log-likelihood. The Wishart distribution is the probability</span>
<span class="sd">    distribution of the maximum-likelihood estimator (MLE) of the covariance</span>
<span class="sd">    matrix of a multivariate normal distribution. If C=1, the distribution</span>
<span class="sd">    is identical to the chi-square distribution with n degrees of freedom.</span>

<span class="sd">    For an alternative parameterization based on :math:`T=C^{-1}`, see</span>
<span class="sd">    `wishart_like`.</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(X \mid n, C) = {\mid C^{-1} \mid}^{n/2}{\mid X \mid}^{(n-k-1)/2} \exp\left\{ -\frac{1}{2} Tr(C^{-1}X) \right\}</span>

<span class="sd">    where :math:`k` is the rank of X.</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      X : matrix</span>
<span class="sd">        Symmetric, positive definite.</span>
<span class="sd">      n : int</span>
<span class="sd">        Degrees of freedom, &gt; 0.</span>
<span class="sd">      C : matrix</span>
<span class="sd">        Symmetric and positive definite</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">flib</span><span class="o">.</span><span class="n">blas_wishart_cov</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>


<span class="c"># -----------------------------------------------------------</span>
<span class="c"># DECORATORS</span>
<span class="c"># -----------------------------------------------------------</span>
</div>
<span class="k">def</span> <span class="nf">name_to_funcs</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">):</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">__dict__</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">logp</span> <span class="o">=</span> <span class="n">module</span><span class="p">[</span><span class="n">name</span> <span class="o">+</span> <span class="s">&quot;_like&quot;</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s">&quot;No likelihood found with this name &quot;</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s">&quot;_like&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">random</span> <span class="o">=</span> <span class="n">module</span><span class="p">[</span><span class="s">&#39;r&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">random</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">grad_logp</span> <span class="o">=</span> <span class="n">module</span><span class="p">[</span><span class="n">name</span> <span class="o">+</span> <span class="s">&quot;_grad_like&quot;</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">grad_logp</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">return</span> <span class="n">logp</span><span class="p">,</span> <span class="n">random</span><span class="p">,</span> <span class="n">grad_logp</span>


<span class="k">def</span> <span class="nf">valuewrapper</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a likelihood accepting value instead of x as a keyword argument.</span>
<span class="sd">    This is specifically intended for the instantiator above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">kwds</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;value&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">arguments</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">__dict__</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">wrapper</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Decorate the likelihoods</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">snapshot</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">likelihoods</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">snapshot</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span> <span class="o">==</span> <span class="s">&#39;_like&#39;</span> <span class="ow">and</span> <span class="n">name</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span> <span class="ow">in</span> <span class="n">availabledistributions</span><span class="p">:</span>
        <span class="n">likelihoods</span><span class="p">[</span><span class="n">name</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]]</span> <span class="o">=</span> <span class="n">snapshot</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">local_decorated_likelihoods</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    New interface likelihoods</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">like</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">likelihoods</span><span class="p">):</span>
        <span class="n">obj</span><span class="p">[</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;_like&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gofwrapper</span><span class="p">(</span><span class="n">like</span><span class="p">,</span> <span class="n">snapshot</span><span class="p">)</span>


<span class="c"># local_decorated_likelihoods(locals())</span>
<span class="c"># Decorating the likelihoods breaks the creation of distribution</span>
<span class="c"># instantiators -DH.</span>

<span class="c"># Create Stochastic instantiators</span>

<span class="k">def</span> <span class="nf">_inject_dist</span><span class="p">(</span><span class="n">distname</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">ns</span><span class="o">=</span><span class="nb">locals</span><span class="p">()):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reusable function to inject Stochastic subclasses into module</span>
<span class="sd">    namespace</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">dist_logp</span><span class="p">,</span> <span class="n">dist_random</span><span class="p">,</span> <span class="n">grad_logp</span> <span class="o">=</span> <span class="n">name_to_funcs</span><span class="p">(</span><span class="n">distname</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
    <span class="n">classname</span> <span class="o">=</span> <span class="n">capitalize</span><span class="p">(</span><span class="n">distname</span><span class="p">)</span>
    <span class="n">ns</span><span class="p">[</span><span class="n">classname</span><span class="p">]</span> <span class="o">=</span> <span class="n">stochastic_from_dist</span><span class="p">(</span><span class="n">distname</span><span class="p">,</span> <span class="n">dist_logp</span><span class="p">,</span>
                                         <span class="n">dist_random</span><span class="p">,</span>
                                         <span class="n">grad_logp</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">sc_continuous_distributions</span><span class="p">:</span>
    <span class="n">_inject_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">mv_continuous_distributions</span><span class="p">:</span>
    <span class="n">_inject_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;mv&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>

<span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">sc_bool_distributions</span><span class="p">:</span>
    <span class="n">_inject_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">})</span>

<span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">sc_discrete_distributions</span><span class="p">:</span>
    <span class="n">_inject_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">})</span>

<span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">mv_discrete_distributions</span><span class="p">:</span>
    <span class="n">_inject_dist</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">,</span> <span class="s">&#39;mv&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">uninformative_like</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uninformative log-likelihood. Returns 0 regardless of the value of x.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">0.</span>


<span class="k">def</span> <span class="nf">one_over_x_like</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    returns -np.Inf if x&lt;0, -np.log(x) otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">Uninformative</span> <span class="o">=</span> <span class="n">stochastic_from_dist</span><span class="p">(</span><span class="s">&#39;uninformative&#39;</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">uninformative_like</span><span class="p">)</span>
<span class="n">DiscreteUninformative</span> <span class="o">=</span> <span class="n">stochastic_from_dist</span><span class="p">(</span>
    <span class="s">&#39;uninformative&#39;</span><span class="p">,</span>
    <span class="n">logp</span><span class="o">=</span><span class="n">uninformative_like</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">DiscreteUninformative</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="s">&#39;DiscreteUninformative&#39;</span>
<span class="n">OneOverX</span> <span class="o">=</span> <span class="n">stochastic_from_dist</span><span class="p">(</span><span class="s">&#39;one_over_x&#39;</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">one_over_x_like</span><span class="p">)</span>

<span class="c"># Conjugates of Dirichlet get special treatment, can be parametrized</span>
<span class="c"># by first k-1 &#39;p&#39; values</span>


<span class="k">def</span> <span class="nf">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    extend_dirichlet(p)</span>

<span class="sd">    Concatenates 1-sum(p) to the end of p and returns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">))))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">mod_categorical_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Categorical log-likelihood with parent p of length k-1.</span>

<span class="sd">    An implicit k&#39;th category  is assumed to exist with associated</span>
<span class="sd">    probability 1-sum(p).</span>

<span class="sd">    ..math::</span>
<span class="sd">        f(x=i \mid p, m, s) = p_i,</span>
<span class="sd">    ..math::</span>
<span class="sd">        i \in 0\ldots k-1</span>

<span class="sd">    :Parameters:</span>
<span class="sd">      x : integer</span>
<span class="sd">        :math: `x \in 0\ldots k-1`</span>
<span class="sd">      p : (k-1) float</span>
<span class="sd">        :math: `p &gt; 0`</span>
<span class="sd">        :math: `\sum p &lt; 1`</span>
<span class="sd">      minval : integer</span>
<span class="sd">      step : integer</span>
<span class="sd">        :math: `s \ge 1`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">categorical_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mod_categorical_expval</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expected value of categorical distribution with parent p of length k-1.</span>

<span class="sd">    An implicit k&#39;th category  is assumed to exist with associated</span>
<span class="sd">    probability 1-sum(p).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">p</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p</span><span class="p">)])</span>


<span class="k">def</span> <span class="nf">rmod_categor</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Categorical random variates with parent p of length k-1.</span>

<span class="sd">    An implicit k&#39;th category  is assumed to exist with associated</span>
<span class="sd">    probability 1-sum(p).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">rcategorical</span><span class="p">(</span><span class="n">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Categorical</span><span class="p">(</span><span class="n">Stochastic</span><span class="p">):</span>
    <span class="n">__doc__</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
<span class="s">C = Categorical(name, p, value=None, dtype=np.int, observed=False,</span>
<span class="s">size=1, trace=True, rseed=False, cache_depth=2, plot=None)</span>

<span class="s">Stochastic variable with Categorical distribution.</span>
<span class="s">Parent is: p</span>

<span class="s">If parent p is Dirichlet and has length k-1, an implicit k&#39;th</span>
<span class="s">category is assumed to exist with associated probability 1-sum(p.value).</span>

<span class="s">Otherwise parent p&#39;s value should sum to 1.</span>

<span class="s">Docstring of categorical_like (case where P is not a Dirichlet):</span>
<span class="s">    &quot;&quot;&quot;</span>\
    <span class="o">+</span> <span class="n">categorical_like</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">+</span>\
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Docstring of categorical_like (case where P is a Dirichlet):</span>
<span class="sd">    &quot;&quot;&quot;</span>\
    <span class="o">+</span> <span class="n">categorical_like</span><span class="o">.</span><span class="n">__doc__</span>

    <span class="n">parent_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;p&#39;</span><span class="p">,</span> <span class="s">&#39;minval&#39;</span><span class="p">,</span> <span class="s">&#39;step&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rseed</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cache_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Dirichlet</span><span class="p">):</span>
            <span class="n">Stochastic</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">valuewrapper</span><span class="p">(</span><span class="n">mod_categorical_like</span><span class="p">),</span>
                                <span class="n">doc</span><span class="o">=</span><span class="s">&#39;A Categorical random variable&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                                <span class="n">parents</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span> <span class="n">random</span><span class="o">=</span><span class="n">bind_size</span><span class="p">(</span><span class="n">rmod_categor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span>
                                <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                <span class="n">rseed</span><span class="o">=</span><span class="n">rseed</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
                                <span class="n">cache_depth</span><span class="o">=</span><span class="n">cache_depth</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Stochastic</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">valuewrapper</span><span class="p">(</span><span class="n">categorical_like</span><span class="p">),</span>
                                <span class="n">doc</span><span class="o">=</span><span class="s">&#39;A Categorical random variable&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                                <span class="n">parents</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                <span class="n">random</span><span class="o">=</span><span class="n">bind_size</span><span class="p">(</span><span class="n">rcategorical</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span>
                                <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                <span class="n">rseed</span><span class="o">=</span><span class="n">rseed</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
                                <span class="n">cache_depth</span><span class="o">=</span><span class="n">cache_depth</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>

<span class="c"># class ModCategorical(Stochastic):</span>
<span class="c">#     __doc__ = &quot;&quot;&quot;</span>
<span class="c"># C = ModCategorical(name, p, minval, step[, trace=True, value=None,</span>
<span class="c">#    rseed=False, observed=False, cache_depth=2, plot=None, verbose=0])</span>
<span class="c">#</span>
<span class="c"># Stochastic variable with ModCategorical distribution.</span>
<span class="c"># Parents are: p, minval, step.</span>
<span class="c">#</span>
<span class="c"># If parent p is Dirichlet and has length k-1, an implicit k&#39;th</span>
<span class="c"># category is assumed to exist with associated probability 1-sum(p.value).</span>
<span class="c">#</span>
<span class="c"># Otherwise parent p&#39;s value should sum to 1.</span>
<span class="c">#</span>
<span class="c"># Docstring of mod_categorical_like (case where P is not a Dirichlet):</span>
<span class="c">#     &quot;&quot;&quot;\</span>
<span class="c">#     + mod_categorical_like.__doc__ +\</span>
<span class="c">#     &quot;&quot;&quot;</span>
<span class="c"># Docstring of mod_categorical_like (case where P is a Dirichlet):</span>
<span class="c">#     &quot;&quot;&quot;\</span>
<span class="c">#     + mod_categorical_like.__doc__</span>
<span class="c">#</span>
<span class="c">#</span>
<span class="c">#     parent_names = [&#39;p&#39;, &#39;minval&#39;, &#39;step&#39;]</span>
<span class="c">#</span>
<span class="c">#     def __init__(self, name, p, minval=0, step=1, value=None, dtype=np.float, observed=False, size=1, trace=True, rseed=False, cache_depth=2, plot=None, verbose=0, **kwds):</span>
<span class="c">#</span>
<span class="c">#         if value is not None:</span>
<span class="c">#             if np.isscalar(value):</span>
<span class="c">#                 self.size = 1</span>
<span class="c">#             else:</span>
<span class="c">#                 self.size = len(value)</span>
<span class="c">#         else:</span>
<span class="c">#             self.size = size</span>
<span class="c">#</span>
<span class="c">#         if isinstance(p, Dirichlet):</span>
<span class="c">#             Stochastic.__init__(self, logp=valuewrapper(mod_categorical_like), doc=&#39;A ModCategorical random variable&#39;, name=name,</span>
<span class="c">#                 parents={&#39;p&#39;:p,&#39;minval&#39;:minval,&#39;step&#39;:step}, random=bind_size(rmod_categor, self.size), trace=trace, value=value, dtype=dtype,</span>
<span class="c">#                 rseed=rseed, observed=observed, cache_depth=cache_depth, plot=plot, verbose=verbose, **kwds)</span>
<span class="c">#         else:</span>
<span class="c">#             Stochastic.__init__(self, logp=valuewrapper(mod_categorical_like), doc=&#39;A ModCategorical random variable&#39;, name=name,</span>
<span class="c">#                 parents={&#39;p&#39;:p,&#39;minval&#39;:minval,&#39;step&#39;:step}, random=bind_size(rmod_categorical, self.size), trace=trace, value=value, dtype=dtype,</span>
<span class="c"># rseed=rseed, observed=observed, cache_depth=cache_depth, plot=plot,</span>
<span class="c"># verbose=verbose, **kwds)</span>


<span class="k">def</span> <span class="nf">mod_rmultinom</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rmultinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mod_multinom_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">multinomial_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">extend_dirichlet</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">Multinomial</span><span class="p">(</span><span class="n">Stochastic</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">M = Multinomial(name, n, p, trace=True, value=None,</span>
<span class="sd">   rseed=False, observed=False, cache_depth=2, plot=None])</span>

<span class="sd">A multinomial random variable. Parents are p, minval, step.</span>

<span class="sd">If parent p is Dirichlet and has length k-1, an implicit k&#39;th</span>
<span class="sd">category is assumed to exist with associated probability 1-sum(p.value).</span>

<span class="sd">Otherwise parent p&#39;s value should sum to 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">parent_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;n&#39;</span><span class="p">,</span> <span class="s">&#39;p&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">rseed</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">observed</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">cache_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Dirichlet</span><span class="p">):</span>
            <span class="n">Stochastic</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">valuewrapper</span><span class="p">(</span><span class="n">mod_multinom_like</span><span class="p">),</span>
                                <span class="n">doc</span><span class="o">=</span><span class="s">&#39;A Multinomial random variable&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                                <span class="n">parents</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;n&#39;</span><span class="p">:</span> <span class="n">n</span><span class="p">,</span> <span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span> <span class="n">random</span><span class="o">=</span><span class="n">mod_rmultinom</span><span class="p">,</span>
                                <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">,</span>
                                <span class="n">rseed</span><span class="o">=</span><span class="n">rseed</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
                                <span class="n">cache_depth</span><span class="o">=</span><span class="n">cache_depth</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Stochastic</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logp</span><span class="o">=</span><span class="n">valuewrapper</span><span class="p">(</span><span class="n">multinomial_like</span><span class="p">),</span>
                                <span class="n">doc</span><span class="o">=</span><span class="s">&#39;A Multinomial random variable&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                                <span class="n">parents</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;n&#39;</span><span class="p">:</span> <span class="n">n</span><span class="p">,</span> <span class="s">&#39;p&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span> <span class="n">random</span><span class="o">=</span><span class="n">rmultinomial</span><span class="p">,</span>
                                <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">,</span>
                                <span class="n">rseed</span><span class="o">=</span><span class="n">rseed</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
                                <span class="n">cache_depth</span><span class="o">=</span><span class="n">cache_depth</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">Impute</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dist_class</span><span class="p">,</span> <span class="n">imputable</span><span class="p">,</span> <span class="o">**</span><span class="n">parents</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function accomodates missing elements for the data of simple</span>
<span class="sd">    Stochastic distribution subclasses. The masked_values argument is an</span>
<span class="sd">    object of type numpy.ma.MaskedArray, which contains the raw data and</span>
<span class="sd">    a boolean mask indicating missing values. The resulting list contains</span>
<span class="sd">    a list of stochastics of type dist_class, with the extant values as data</span>
<span class="sd">    stochastics and the missing values as variable stochastics.</span>

<span class="sd">    :Arguments:</span>
<span class="sd">      - name : string</span>
<span class="sd">        Name of the data stochastic</span>
<span class="sd">      - dist_class : Stochastic</span>
<span class="sd">        Stochastic subclass such as Poisson, Normal, etc.</span>
<span class="sd">      - imputable : numpy.ma.core.MaskedArray or iterable</span>
<span class="sd">        A masked array with missing elements (where mask=True, value</span>
<span class="sd">        is assumed missing), or any iterable that contains None</span>
<span class="sd">        elements that will be imputed.</span>
<span class="sd">      - parents (optional): dict</span>
<span class="sd">        Arbitrary keyword arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">imputable</span><span class="p">)</span>
    <span class="n">masked_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">imputable</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">masked_values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">):</span>
        <span class="c"># Generate mask</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">masked_values</span><span class="p">]</span>
        <span class="c"># Generate masked array</span>
        <span class="n">masked_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">masked_values</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="c"># Initialise list</span>
    <span class="nb">vars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">masked_values</span><span class="p">)):</span>

        <span class="c"># Name of element</span>
        <span class="n">this_name</span> <span class="o">=</span> <span class="n">name</span> <span class="o">+</span> <span class="s">&#39;[</span><span class="si">%i</span><span class="s">]&#39;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="c"># Dictionary to hold parents</span>
        <span class="n">these_parents</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c"># Parse parents</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">parent</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">parents</span><span class="p">):</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c"># If parent is a PyMCObject</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">shape</span> <span class="o">==</span> <span class="n">dims</span><span class="p">:</span>
                <span class="n">these_parents</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">&#39;[</span><span class="si">%i</span><span class="s">]&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
                                            <span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">parent</span><span class="p">),</span>
                                            <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">shape</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">masked_values</span><span class="p">):</span>
                <span class="n">these_parents</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">&#39;[</span><span class="si">%i</span><span class="s">]&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">parent</span><span class="p">,</span>
                                            <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">these_parents</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">parent</span>

        <span class="k">if</span> <span class="n">masked_values</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="c"># Missing values</span>
            <span class="nb">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist_class</span><span class="p">(</span><span class="n">this_name</span><span class="p">,</span> <span class="o">**</span><span class="n">these_parents</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Observed values</span>
            <span class="nb">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist_class</span><span class="p">(</span><span class="n">this_name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">masked_values</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                   <span class="n">observed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">these_parents</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">vars</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>

<span class="n">ImputeMissing</span> <span class="o">=</span> <span class="n">Impute</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">()</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/icon.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">PyMC 2.3.4 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, Christopher J. Fonnesbeck.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>